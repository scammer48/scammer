import logging
import asyncio
import time
import traceback
from datetime import datetime, timedelta, date
from typing import Dict, Optional, Any, List
from performance import global_cache

from database import db


logger = logging.getLogger("GroupCheckInBot.DualShiftReset")


# ========== 1. è°ƒåº¦å…¥å£ ==========
async def handle_hard_reset(
    chat_id: int,
    operator_id: Optional[int] = None,
    target_date: Optional[date] = None,
) -> bool:
    """
    ç¡¬é‡ç½®æ€»è°ƒåº¦å…¥å£ - çº¯åŒç­æ¨¡å¼
    """
    try:
        logger.info(f"ğŸ”„ [åŒç­æ¨¡å¼] ç¾¤ç»„ {chat_id} æ‰§è¡ŒåŒç­ç¡¬é‡ç½®")

        if target_date:
            success = await _dual_shift_hard_reset(chat_id, operator_id, target_date)
        else:
            success = await _dual_shift_hard_reset(chat_id, operator_id)

        if success:
            logger.info(f"âœ… [åŒç­ç¡¬é‡ç½®] ç¾¤ç»„ {chat_id} æ‰§è¡ŒæˆåŠŸ")
        else:
            logger.error(f"âŒ [åŒç­ç¡¬é‡ç½®] ç¾¤ç»„ {chat_id} æ‰§è¡Œå¤±è´¥")

        return success

    except Exception as e:
        logger.error(f"âŒ [åŒç­ç¡¬é‡ç½®] ç¾¤ç»„ {chat_id} å¼‚å¸¸: {e}")
        logger.error(traceback.format_exc())
        return False


# ========== 2. åŒç­ç¡¬é‡ç½®æ ¸å¿ƒæµç¨‹ ==========
async def _dual_shift_hard_reset(
    chat_id: int,
    operator_id: Optional[int] = None,
    forced_target_date: Optional[date] = None,
) -> bool:
    """åŒç­ç¡¬é‡ç½®ä¸»æµç¨‹ï¼ˆå¸¦å¹‚ç­‰æ€§ï¼‰"""
    try:
        now = db.get_beijing_time()

        date_range = await db.get_business_date_range(chat_id, now)
        business_today = date_range["business_today"]
        business_yesterday = date_range["business_yesterday"]
        business_day_before = date_range["business_day_before"]
        natural_today = date_range["natural_today"]

        logger.info(
            f"ğŸ“… [åŒç­é‡ç½®] æ—¥æœŸä¿¡æ¯:\n"
            f"   â€¢ è‡ªç„¶ä»Šå¤©: {natural_today}\n"
            f"   â€¢ ä¸šåŠ¡ä»Šå¤©: {business_today}\n"
            f"   â€¢ ä¸šåŠ¡æ˜¨å¤©: {business_yesterday}"
        )

        if forced_target_date:
            target_date = forced_target_date
            logger.info(f"ğŸ¯ [åŒç­é‡ç½®] ä½¿ç”¨å¼ºåˆ¶ç›®æ ‡æ—¥æœŸ: {target_date}")
        else:
            group_data = await db.get_group_cached(chat_id)
            reset_hour = group_data.get("reset_hour", 0)
            reset_minute = group_data.get("reset_minute", 0)

            reset_time_natural_today = datetime.combine(
                natural_today,
                datetime.strptime(
                    f"{reset_hour:02d}:{reset_minute:02d}", "%H:%M"
                ).time(),
            ).replace(tzinfo=now.tzinfo)

            execute_time_today = reset_time_natural_today + timedelta(hours=2)

            reset_time_natural_yesterday = datetime.combine(
                natural_today - timedelta(days=1),
                datetime.strptime(
                    f"{reset_hour:02d}:{reset_minute:02d}", "%H:%M"
                ).time(),
            ).replace(tzinfo=now.tzinfo)

            execute_time_yesterday = reset_time_natural_yesterday + timedelta(hours=2)

            EXECUTION_WINDOW = 300

            time_to_today = abs((now - execute_time_today).total_seconds())
            time_to_yesterday = abs((now - execute_time_yesterday).total_seconds())

            if time_to_today <= EXECUTION_WINDOW:
                target_date = business_yesterday
                period_info = "æ­£å¸¸æ‰§è¡Œ"
                logger.info(f"ğŸ“… æ­£å¸¸æ‰§è¡Œçª—å£ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
            elif time_to_yesterday <= EXECUTION_WINDOW:
                target_date = business_yesterday
                period_info = "è¡¥æ‰§è¡Œ"
                logger.warning(f"âš ï¸ è¡¥æ‰§è¡Œåœºæ™¯ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
            else:
                logger.debug(f"â³ ä¸åœ¨æ‰§è¡Œçª—å£å†…")
                return False

        reset_flag_key = f"dual_reset:{chat_id}:{target_date.strftime('%Y%m%d')}"
        if global_cache.get(reset_flag_key):
            logger.info(f"â­ï¸ ç¾¤ç»„ {chat_id} ä»Šå¤©å·²å®ŒæˆåŒç­é‡ç½®ï¼Œè·³è¿‡")
            return True

        await db.init_group(chat_id)
        group_data = await db.get_group_cached(chat_id)
        if not group_data:
            logger.warning(f"âš ï¸ [åŒç­ç¡¬é‡ç½®] ç¾¤ç»„ {chat_id} æ²¡æœ‰é…ç½®æ•°æ®ï¼Œè·³è¿‡é‡ç½®")
            return False

        reset_hour = group_data.get("reset_hour", 0)
        reset_minute = group_data.get("reset_minute", 0)

        logger.info(
            f"ğŸš€ [åŒç­ç¡¬é‡ç½®] å¼€å§‹æ‰§è¡Œ\n"
            f"   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            f"   â”œâ”€ ç¾¤ç»„ID: {chat_id}\n"
            f"   â”œâ”€ å½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"   â”œâ”€ è‡ªç„¶ä»Šå¤©: {natural_today}\n"
            f"   â”œâ”€ ä¸šåŠ¡ä»Šå¤©: {business_today}\n"
            f"   â”œâ”€ ç›®æ ‡æ—¥æœŸ: {target_date}\n"
            f"   â”œâ”€ é‡ç½®æ—¶é—´: {reset_hour:02d}:{reset_minute:02d}\n"
            f"   â””â”€ æ“ä½œå‘˜: {operator_id or 'ç³»ç»Ÿ'}"
        )

        total_start_time = time.time()

        force_stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "day_shift": {"total": 0, "success": 0, "failed": 0},
            "night_shift": {"total": 0, "success": 0, "failed": 0},
            "details": [],
        }

        complete_stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "day_shift": {"total": 0, "success": 0, "failed": 0},
            "night_shift": {"total": 0, "success": 0, "failed": 0},
            "details": [],
        }

        logger.info(f"ğŸ“Š [æ­¥éª¤1-2/5] å¹¶å‘å¤„ç†æœªå®Œæˆæ´»åŠ¨åŠè¡¥å…¨ä¸‹ç­è®°å½•...")
        task1 = asyncio.create_task(
            _force_end_all_unfinished_shifts(chat_id, now, target_date, business_today)
        )
        task2 = asyncio.create_task(
            _complete_missing_work_ends(chat_id, target_date, business_today)
        )

        results = await asyncio.gather(task1, task2, return_exceptions=True)

        if not isinstance(results[0], Exception):
            force_stats = results[0]
            logger.info(
                f"âœ… å¼ºåˆ¶ç»“æŸæ´»åŠ¨å®Œæˆ: {force_stats['success']}/{force_stats['total']}"
            )
        else:
            logger.error(f"âŒ [å¼ºåˆ¶ç»“æŸæ´»åŠ¨] å¤±è´¥: {results[0]}")
            logger.error(traceback.format_exc())

        if not isinstance(results[1], Exception):
            complete_stats = results[1]
            logger.info(
                f"âœ… è¡¥å…¨ä¸‹ç­è®°å½•å®Œæˆ: {complete_stats['success']}/{complete_stats['total']}"
            )
        else:
            logger.error(f"âŒ [è¡¥å…¨ä¸‹ç­è®°å½•] å¤±è´¥: {results[1]}")
            logger.error(traceback.format_exc())

        logger.info(f"ğŸ“Š [æ­¥éª¤3/5] å¯¼å‡ºç›®æ ‡æ—¥æœŸæ•°æ®...")
        export_start = time.time()
        try:
            export_success = await _export_yesterday_data_concurrent(
                chat_id, target_date
            )
        except Exception as e:
            logger.error(f"âŒ [æ•°æ®å¯¼å‡º] å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            export_success = False
        export_time = time.time() - export_start

        logger.info(f"ğŸ“Š [æ­¥éª¤4/5] æ¸…é™¤ç›®æ ‡æ—¥æœŸæ•°æ®...")
        cleanup_start = time.time()
        try:
            cleanup_stats = await _cleanup_old_data(
                chat_id, target_date, business_today
            )
        except Exception as e:
            logger.error(f"âŒ [æ•°æ®æ¸…ç†] å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            cleanup_stats = {
                "user_activities": 0,
                "work_records": 0,
                "daily_statistics": 0,
                "users_reset": 0,
            }
        cleanup_time = time.time() - cleanup_start

        deleted_count = 0
        try:
            if not db.pool or not db._initialized:
                logger.error("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
                return
            async with db.pool.acquire() as conn:
                result = await conn.execute(
                    """
                    DELETE FROM group_shift_state 
                    WHERE chat_id = $1 AND record_date < $2
                    """,
                    chat_id,
                    business_today,
                )
                deleted_count = _parse_delete_count(result)

                if deleted_count > 0:
                    logger.info(f"âœ… å·²æ¸…é™¤ {deleted_count} ä¸ªè¿‡æœŸç­æ¬¡çŠ¶æ€")

                    keys_to_remove = [
                        key
                        for key in db._cache.keys()
                        if key.startswith(f"shift_state:{chat_id}:")
                    ]
                    for key in keys_to_remove:
                        db._cache.pop(key, None)
                        db._cache_ttl.pop(key, None)
                else:
                    logger.info("âœ… æ²¡æœ‰éœ€è¦æ¸…é™¤çš„ç­æ¬¡çŠ¶æ€")

        except Exception as e:
            logger.error(f"âŒ [æ¸…é™¤ç­æ¬¡çŠ¶æ€] å¤±è´¥: {e}")

        try:
            asyncio.create_task(
                _send_reset_notification(
                    chat_id,
                    force_stats,
                    complete_stats,
                    export_success,
                    cleanup_stats,
                    now,
                )
            )
        except Exception as e:
            logger.error(f"âŒ [å‘é€é€šçŸ¥] å¤±è´¥: {e}")

        global_cache.set(reset_flag_key, True, ttl=86400)
        logger.info(f"âœ… [åŒç­é‡ç½®] ç¾¤ç»„ {chat_id} æ‰§è¡ŒæˆåŠŸï¼Œå·²è®¾ç½®å¹‚ç­‰æ ‡è®°")

        total_time = time.time() - total_start_time
        logger.info(
            f"ğŸ‰ [åŒç­ç¡¬é‡ç½®å®Œæˆ] ç¾¤ç»„ {chat_id}\n"
            f"   â”œâ”€ ç›®æ ‡æ—¥æœŸ: {target_date}\n"
            f"   â”œâ”€ å¼ºåˆ¶ç»“æŸ: {force_stats['success']}/{force_stats['total']}\n"
            f"   â”œâ”€ è¡¥å…¨ä¸‹ç­: {complete_stats['success']}/{complete_stats['total']}\n"
            f"   â”œâ”€ å¯¼å‡ºæˆåŠŸ: {export_success}\n"
            f"   â”œâ”€ æ¸…ç†è®°å½•: {cleanup_stats.get('user_activities', 0)}æ¡\n"
            f"   â”œâ”€ æ¸…é™¤ç­æ¬¡çŠ¶æ€: {deleted_count}ä¸ª\n"
            f"   â””â”€ æ€»è€—æ—¶: {total_time:.2f}ç§’"
        )

        return True

    except Exception as e:
        logger.error(
            f"âŒ [åŒç­ç¡¬é‡ç½®] å¤±è´¥ {chat_id}\n"
            f"   â”œâ”€ é”™è¯¯ç±»å‹: {type(e).__name__}\n"
            f"   â”œâ”€ é”™è¯¯ä¿¡æ¯: {e}\n"
            f"   â””â”€ å †æ ˆ: {traceback.format_exc()}"
        )
        return False


# ========== 3. ç»Ÿä¸€å¼ºåˆ¶ç»“æŸæ‰€æœ‰æœªå®Œæˆæ´»åŠ¨ ==========
async def _force_end_all_unfinished_shifts(
    chat_id: int, now: datetime, target_date: date, business_today: date
) -> Dict[str, Any]:
    """å¼ºåˆ¶ç»“æŸæ‰€æœ‰è¿›è¡Œä¸­çš„æ´»åŠ¨ï¼ˆåªç»“æŸä¸šåŠ¡æ˜¨å¤©åŠä¹‹å‰å¼€å§‹çš„æ´»åŠ¨ï¼‰"""
    stats = {
        "total": 0,
        "success": 0,
        "failed": 0,
        "day_shift": {"total": 0, "success": 0, "failed": 0},
        "night_shift": {"total": 0, "success": 0, "failed": 0},
        "details": [],
    }

    try:
        if not db.pool or not db._initialized:
            logger.error("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
            return
        async with db.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT user_id, nickname, current_activity, 
                       activity_start_time, shift
                FROM users 
                WHERE chat_id = $1 
                  AND current_activity IS NOT NULL
                """,
                chat_id,
            )

            stats["total"] = len(rows)

            if not rows:
                logger.info(f"ğŸ“Š ç¾¤ç»„ {chat_id} æ²¡æœ‰è¿›è¡Œä¸­çš„æ´»åŠ¨")
                return stats

            logger.info(f"ğŸ“Š å‘ç° {len(rows)} ä¸ªè¿›è¡Œä¸­çš„æ´»åŠ¨ï¼Œå¼€å§‹å¹¶å‘å¤„ç†...")

            tasks = []
            for row in rows:
                task = asyncio.create_task(
                    _force_end_single_activity(
                        conn, chat_id, row, now, target_date, business_today
                    )
                )
                tasks.append(task)

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    stats["failed"] += 1
                    if rows[i]["shift"] == "day":
                        stats["day_shift"]["failed"] += 1
                    else:
                        stats["night_shift"]["failed"] += 1
                    logger.error(f"âŒ å¤„ç†ç”¨æˆ· {rows[i]['user_id']} å¤±è´¥: {result}")
                else:
                    stats["success"] += 1
                    if result["shift"] == "day":
                        stats["day_shift"]["success"] += 1
                    else:
                        stats["night_shift"]["success"] += 1
                    stats["details"].append(result)

            stats["day_shift"]["total"] = sum(1 for r in rows if r["shift"] == "day")
            stats["night_shift"]["total"] = sum(
                1 for r in rows if r["shift"] == "night"
            )

        logger.info(
            f"âœ… [å¼ºåˆ¶ç»“æŸæ´»åŠ¨å®Œæˆ] ç¾¤ç»„ {chat_id}\n"
            f"   â”œâ”€ æ€»è®¡: {stats['total']} äºº\n"
            f"   â”œâ”€ æˆåŠŸ: {stats['success']} äºº\n"
            f"   â”œâ”€ å¤±è´¥: {stats['failed']} äºº\n"
            f"   â”œâ”€ ç™½ç­: {stats['day_shift']['success']}/{stats['day_shift']['total']}\n"
            f"   â””â”€ å¤œç­: {stats['night_shift']['success']}/{stats['night_shift']['total']}"
        )

    except Exception as e:
        logger.error(f"âŒ [å¼ºåˆ¶ç»“æŸæ´»åŠ¨] å¤±è´¥ {chat_id}: {e}")
        logger.error(traceback.format_exc())

    return stats


async def _force_end_single_activity(
    conn,
    chat_id: int,
    user_row: dict,
    now: datetime,
    target_date: date,
    business_today: date,
) -> Dict[str, Any]:
    """å¼ºåˆ¶ç»“æŸå•ä¸ªæ´»åŠ¨"""
    result = {
        "user_id": user_row["user_id"],
        "shift": user_row["shift"],
        "activity": user_row["current_activity"],
        "elapsed": 0,
        "fine": 0,
        "is_overtime": False,
        "success": False,
    }

    try:
        activity = user_row["current_activity"]
        start_time = datetime.fromisoformat(user_row["activity_start_time"])
        start_date = start_time.date()

        if start_date < business_today:
            if start_date <= target_date:
                forced_date = target_date
            else:
                forced_date = business_today - timedelta(days=1)
        else:
            logger.debug(f"â­ï¸ ä¿ç•™ä»Šå¤©æ´»åŠ¨: ç”¨æˆ·{user_row['user_id']}")
            result["success"] = True
            return result

        elapsed = int((now - start_time).total_seconds())

        time_limit = await db.get_activity_time_limit(activity)
        time_limit_seconds = time_limit * 60
        is_overtime = elapsed > time_limit_seconds
        overtime_seconds = max(0, elapsed - time_limit_seconds)
        overtime_minutes = overtime_seconds / 60

        fine_amount = 0
        if is_overtime and overtime_seconds > 0:
            fine_rates = await db.get_fine_rates_for_activity(activity)
            if fine_rates:
                segments = []
                for k in fine_rates.keys():
                    try:
                        v = int(str(k).lower().replace("min", ""))
                        segments.append(v)
                    except:
                        pass
                segments.sort()
                for s in segments:
                    if overtime_minutes <= s:
                        fine_amount = fine_rates.get(
                            str(s), fine_rates.get(f"{s}min", 0)
                        )
                        break
                if fine_amount == 0 and segments:
                    m = segments[-1]
                    fine_amount = fine_rates.get(str(m), fine_rates.get(f"{m}min", 0))

        result["elapsed"] = elapsed
        result["fine"] = fine_amount
        result["is_overtime"] = is_overtime

        await db.complete_user_activity(
            chat_id=chat_id,
            user_id=user_row["user_id"],
            activity=activity,
            elapsed_time=elapsed,
            fine_amount=fine_amount,
            is_overtime=is_overtime,
            shift=user_row["shift"],
            forced_date=forced_date,
        )

        result["success"] = True

        logger.info(
            f"âœ… [å¼ºåˆ¶ç»“æŸ] ç”¨æˆ·{user_row['user_id']} | "
            f"æ´»åŠ¨:{activity} | ç­æ¬¡:{user_row['shift']} | "
            f"å½’åˆ°:{forced_date} | æ—¶é•¿:{elapsed}s | ç½šæ¬¾:{fine_amount}"
        )

    except Exception as e:
        logger.error(f"âŒ [å¼ºåˆ¶ç»“æŸ] ç”¨æˆ·{user_row['user_id']} å¤±è´¥: {e}")
        raise

    return result


# ========== 4. è¡¥å…¨æœªæ‰“å¡çš„ä¸‹ç­è®°å½• ==========
async def _complete_missing_work_ends(
    chat_id: int, target_date: date, business_today: date
) -> Dict[str, Any]:
    """ä¸ºæ˜¨å¤©æœ‰ä¸Šç­è®°å½•ä½†æ²¡æœ‰ä¸‹ç­è®°å½•çš„ç”¨æˆ·è¡¥å…¨ä¸‹ç­è®°å½•"""
    stats = {
        "total": 0,
        "success": 0,
        "failed": 0,
        "day_shift": {"total": 0, "success": 0, "failed": 0},
        "night_shift": {"total": 0, "success": 0, "failed": 0},
        "details": [],
    }

    try:
        if not db.pool or not db._initialized:
            logger.error("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
            return
        async with db.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT 
                    wr.user_id,
                    wr.shift,
                    wr.shift_detail,
                    wr.checkin_time as work_start_time,
                    u.nickname
                FROM work_records wr
                JOIN users u ON wr.chat_id = u.chat_id AND wr.user_id = u.user_id
                WHERE wr.chat_id = $1
                  AND wr.record_date = $2
                  AND wr.checkin_type = 'work_start'
                  AND NOT EXISTS(
                      SELECT 1 FROM work_records wr2
                      WHERE wr2.chat_id = wr.chat_id
                        AND wr2.user_id = wr.user_id
                        AND wr2.record_date = wr.record_date
                        AND wr2.shift = wr.shift
                        AND wr2.checkin_type = 'work_end'
                  )
                """,
                chat_id,
                target_date,
            )

            stats["total"] = len(rows)

            if not rows:
                logger.info(f"ğŸ“ ç¾¤ç»„ {chat_id} æ˜¨æ—¥æ²¡æœ‰æœªä¸‹ç­çš„ç”¨æˆ·")
                return stats

            logger.info(f"ğŸ“ å‘ç° {len(rows)} ä¸ªæ˜¨æ—¥æœªä¸‹ç­çš„ç”¨æˆ·ï¼Œå¼€å§‹è¡¥å…¨è®°å½•...")

            group_data = await db.get_group_cached(chat_id)
            reset_hour = group_data.get("reset_hour", 0)
            reset_minute = group_data.get("reset_minute", 0)
            auto_end_time = f"{reset_hour:02d}:{reset_minute:02d}"

            shift_config = await db.get_shift_config(chat_id)

            tasks = []
            for row in rows:
                task = asyncio.create_task(
                    _complete_single_work_end(
                        conn, chat_id, row, target_date, auto_end_time, shift_config
                    )
                )
                tasks.append(task)

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    stats["failed"] += 1
                    if rows[i]["shift"] == "day":
                        stats["day_shift"]["failed"] += 1
                    else:
                        stats["night_shift"]["failed"] += 1
                    logger.error(
                        f"âŒ è¡¥å…¨ç”¨æˆ· {rows[i]['user_id']} ä¸‹ç­è®°å½•å¤±è´¥: {result}"
                    )
                else:
                    stats["success"] += 1
                    if result["shift"] == "day":
                        stats["day_shift"]["success"] += 1
                    else:
                        stats["night_shift"]["success"] += 1
                    stats["details"].append(result)

            stats["day_shift"]["total"] = sum(1 for r in rows if r["shift"] == "day")
            stats["night_shift"]["total"] = sum(
                1 for r in rows if r["shift"] == "night"
            )

        logger.info(
            f"âœ… [è¡¥å…¨ä¸‹ç­è®°å½•å®Œæˆ] ç¾¤ç»„ {chat_id}\n"
            f"   â”œâ”€ æ€»è®¡: {stats['total']} äºº\n"
            f"   â”œâ”€ æˆåŠŸ: {stats['success']} äºº\n"
            f"   â”œâ”€ å¤±è´¥: {stats['failed']} äºº\n"
            f"   â”œâ”€ ç™½ç­: {stats['day_shift']['success']}/{stats['day_shift']['total']}\n"
            f"   â””â”€ å¤œç­: {stats['night_shift']['success']}/{stats['night_shift']['total']}"
        )

    except Exception as e:
        logger.error(f"âŒ [è¡¥å…¨ä¸‹ç­è®°å½•] å¤±è´¥ {chat_id}: {e}")
        logger.error(traceback.format_exc())

    return stats


async def _complete_single_work_end(
    conn,
    chat_id: int,
    row: dict,
    target_date: date,
    auto_end_time: str,
    shift_config: dict,
) -> Dict[str, Any]:
    """è¡¥å•å•ä¸ªç”¨æˆ·çš„ä¸‹ç­è®°å½•"""
    result = {
        "user_id": row["user_id"],
        "shift": row["shift"],
        "work_start_time": row["work_start_time"],
        "work_end_time": auto_end_time,
        "fine": 0,
        "success": False,
    }

    try:
        if row["shift"] == "day":
            expected_end_time = shift_config.get("day_end", "18:00")
            work_end_date = target_date
        else:
            expected_end_time = shift_config.get("day_start", "09:00")
            work_end_date = target_date + timedelta(days=1)

        work_start_time = datetime.strptime(row["work_start_time"], "%H:%M").time()
        work_start_dt = datetime.combine(target_date, work_start_time)

        expected_end_dt = datetime.combine(
            work_end_date, datetime.strptime(expected_end_time, "%H:%M").time()
        )

        auto_end_dt = datetime.combine(
            work_end_date, datetime.strptime(auto_end_time, "%H:%M").time()
        )

        time_diff_seconds = int((auto_end_dt - expected_end_dt).total_seconds())
        time_diff_minutes = time_diff_seconds / 60

        fine_amount = 0
        if time_diff_seconds < 0:
            fine_rates = await db.get_work_fine_rates_for_type("work_end")
            if fine_rates:
                thresholds = sorted([int(k) for k in fine_rates.keys()])
                for threshold in thresholds:
                    if abs(time_diff_minutes) >= threshold:
                        fine_amount = fine_rates[str(threshold)]

        work_duration = int((auto_end_dt - work_start_dt).total_seconds())

        if time_diff_seconds < 0:
            status = f"ğŸš¨ è‡ªåŠ¨ä¸‹ç­ï¼ˆæ—©é€€ {abs(time_diff_minutes):.1f}åˆ†é’Ÿï¼‰"
        elif time_diff_seconds > 0:
            status = f"âœ… è‡ªåŠ¨ä¸‹ç­ï¼ˆåŠ ç­ {time_diff_minutes:.1f}åˆ†é’Ÿï¼‰"
        else:
            status = "âœ… è‡ªåŠ¨ä¸‹ç­ï¼ˆå‡†æ—¶ï¼‰"

        await db.add_work_record(
            chat_id=chat_id,
            user_id=row["user_id"],
            record_date=target_date,
            checkin_type="work_end",
            checkin_time=auto_end_time,
            status=status,
            time_diff_minutes=time_diff_minutes,
            fine_amount=fine_amount,
            shift=row["shift"],
            shift_detail=row.get("shift_detail", row["shift"]),
        )

        await conn.execute(
            """
            INSERT INTO daily_statistics
            (chat_id, user_id, record_date, activity_name, accumulated_time, shift)
            VALUES ($1, $2, $3, 'work_hours', $4, $5)
            ON CONFLICT (chat_id, user_id, record_date, activity_name, shift)
            DO UPDATE SET
                accumulated_time = daily_statistics.accumulated_time + EXCLUDED.accumulated_time,
                updated_at = CURRENT_TIMESTAMP
            """,
            chat_id,
            row["user_id"],
            target_date,
            work_duration,
            row["shift"],
        )

        result["fine"] = fine_amount
        result["success"] = True

        logger.info(
            f"âœ… [è¡¥å…¨ä¸‹ç­] ç”¨æˆ·{row['user_id']} | "
            f"ç­æ¬¡:{row['shift']} | ä¸Šç­:{row['work_start_time']} | "
            f"è‡ªåŠ¨ä¸‹ç­:{auto_end_time} | ç½šæ¬¾:{fine_amount}"
        )

    except Exception as e:
        logger.error(f"âŒ [è¡¥å…¨ä¸‹ç­] ç”¨æˆ·{row['user_id']} å¤±è´¥: {e}")
        raise

    return result


# ========== 5. å¯¼å‡ºæ•°æ® ==========
async def _export_yesterday_data_concurrent(
    chat_id: int, target_date: date, from_monthly: bool = False
) -> bool:
    """å¹¶å‘å¯¼å‡ºæ•°æ®ï¼ŒæˆåŠŸä¸€æ¬¡å°±æ¨é€"""
    from main import export_and_push_csv

    source = "æœˆåº¦è¡¨" if from_monthly else "æ—¥å¸¸è¡¨"
    already_sent = False
    success_count = 0

    async def task_wrapper(attempt: int) -> bool:
        nonlocal already_sent
        file_name = f"dual_shift_backup_{chat_id}_{target_date.strftime('%Y%m%d')}.csv"
        push_file = not already_sent

        try:
            result = await export_and_push_csv(
                chat_id=chat_id,
                target_date=target_date,
                file_name=file_name,
                is_daily_reset=True,
                from_monthly_table=True,
                push_file=push_file,
            )

            if result:
                if not already_sent:
                    already_sent = True
                    logger.info(
                        f"âœ… [æ•°æ®å¯¼å‡º] ç¾¤ç»„{chat_id} ç¬¬{attempt+1}æ¬¡å°è¯•æˆåŠŸï¼Œå·²æ¨é€"
                    )
                else:
                    logger.info(
                        f"âœ… [æ•°æ®å¯¼å‡º] ç¾¤ç»„{chat_id} ç¬¬{attempt+1}æ¬¡å°è¯•æˆåŠŸï¼Œå·²è·³è¿‡"
                    )
                return True
            return False

        except Exception as e:
            logger.warning(f"âš ï¸ [æ•°æ®å¯¼å‡º] ç¬¬{attempt+1}æ¬¡å°è¯•å¤±è´¥: {e}")
            return False

    tasks = [asyncio.create_task(task_wrapper(i)) for i in range(3)]
    results = await asyncio.gather(*tasks)
    success_count = sum(1 for r in results if r is True)

    if already_sent:
        logger.info(f"ğŸ“Š [æ•°æ®å¯¼å‡º] ç¾¤ç»„{chat_id} å…± {success_count} æ¬¡æˆåŠŸï¼Œå·²æ¨é€1æ¬¡")
        return True
    else:
        logger.error(f"âŒ [æ•°æ®å¯¼å‡º] ç¾¤ç»„{chat_id} æ‰€æœ‰3æ¬¡å°è¯•å‡å¤±è´¥")
        return False


# ========== 6. æ•°æ®æ¸…ç† ==========
async def _cleanup_old_data(
    chat_id: int, target_date: date, business_today: date
) -> Dict[str, int]:
    """æ•°æ®æ¸…ç†"""
    stats = {
        "user_activities": 0,
        "work_records": 0,
        "daily_statistics": 0,
        "users_reset": 0,
    }

    try:
        if not db.pool or not db._initialized:
            logger.error("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
            return
        async with db.pool.acquire() as conn:
            async with conn.transaction():
                result = await conn.execute(
                    """
                    DELETE FROM user_activities 
                    WHERE chat_id = $1 AND activity_date = $2
                    """,
                    chat_id,
                    target_date,
                )
                stats["user_activities"] = _parse_delete_count(result)

                result = await conn.execute(
                    """
                    DELETE FROM work_records 
                    WHERE chat_id = $1 AND record_date = $2
                    """,
                    chat_id,
                    target_date,
                )
                stats["work_records"] = _parse_delete_count(result)

                result = await conn.execute(
                    """
                    DELETE FROM daily_statistics 
                    WHERE chat_id = $1 AND record_date = $2
                    """,
                    chat_id,
                    target_date,
                )
                stats["daily_statistics"] = _parse_delete_count(result)

                result = await conn.execute(
                    """
                    UPDATE users 
                    SET current_activity = NULL, 
                        activity_start_time = NULL,
                        last_updated = $2
                    WHERE chat_id = $1 
                      AND last_updated <= $3
                      AND current_activity IS NOT NULL
                    """,
                    chat_id,
                    business_today,
                    target_date,
                )
                stats["users_reset"] = _parse_update_count(result)

        total_deleted = (
            stats["user_activities"] + stats["work_records"] + stats["daily_statistics"]
        )

        logger.info(
            f"ğŸ§¹ [æ•°æ®æ¸…ç†] ç¾¤ç»„{chat_id}\n"
            f"   â€¢ åˆ é™¤ç”¨æˆ·æ´»åŠ¨: {stats['user_activities']} æ¡\n"
            f"   â€¢ åˆ é™¤å·¥ä½œè®°å½•: {stats['work_records']} æ¡\n"
            f"   â€¢ åˆ é™¤æ—¥ç»Ÿè®¡: {stats['daily_statistics']} æ¡\n"
            f"   â€¢ é‡ç½®ç”¨æˆ·çŠ¶æ€: {stats['users_reset']} äºº\n"
            f"   â€¢ æ€»è®¡åˆ é™¤: {total_deleted} æ¡\n"
            f"   â€¢ ä»Šå¤©æ•°æ®: âœ… å®Œæ•´ä¿ç•™ (ä¸šåŠ¡ä»Šå¤© = {business_today})"
        )

    except Exception as e:
        logger.error(f"âŒ [æ•°æ®æ¸…ç†] å¤±è´¥ {chat_id}: {e}")
        logger.error(traceback.format_exc())

    return stats


# ========== 7. å‘é€é€šçŸ¥ ==========
async def _send_reset_notification(
    chat_id: int,
    force_stats: Dict[str, Any],
    complete_stats: Dict[str, Any],
    export_success: bool,
    cleanup_stats: Dict[str, int],
    reset_time: datetime,
):
    """å‘é€é‡ç½®é€šçŸ¥"""
    try:
        from main import send_reset_notification

        notification_data = {
            "force_activities": force_stats,
            "complete_records": complete_stats,
            "export": export_success,
            "cleanup": cleanup_stats,
            "reset_time": reset_time.strftime("%Y-%m-%d %H:%M:%S"),
            "day_shift": {
                "forced": force_stats.get("day_shift", {}).get("success", 0),
                "completed": complete_stats.get("day_shift", {}).get("success", 0),
            },
            "night_shift": {
                "forced": force_stats.get("night_shift", {}).get("success", 0),
                "completed": complete_stats.get("night_shift", {}).get("success", 0),
            },
        }

        await send_reset_notification(chat_id, notification_data, reset_time)
        logger.info(f"   âœ… é‡ç½®é€šçŸ¥å·²å‘é€")

    except Exception as e:
        logger.warning(f"   âš ï¸ å‘é€é‡ç½®é€šçŸ¥å¤±è´¥: {e}")


# ========== 8. è¾…åŠ©å‡½æ•° ==========
def _parse_delete_count(result: str) -> int:
    """è§£æ DELETE è¯­å¥è¿”å›çš„è¡Œæ•°"""
    if not result or not isinstance(result, str):
        return 0
    try:
        parts = result.split()
        if len(parts) >= 2 and parts[0] == "DELETE":
            return int(parts[-1])
    except (ValueError, IndexError):
        pass
    return 0


def _parse_update_count(result: str) -> int:
    """è§£æ UPDATE è¯­å¥è¿”å›çš„è¡Œæ•°"""
    if not result or not isinstance(result, str):
        return 0
    try:
        parts = result.split()
        if len(parts) >= 2 and parts[0] == "UPDATE":
            return int(parts[-1])
    except (ValueError, IndexError):
        pass
    return 0


# ========== 9. æ¢å¤ç­æ¬¡çŠ¶æ€ ==========
async def recover_shift_states():
    """ç³»ç»Ÿå¯åŠ¨æ—¶æ¢å¤æ‰€æœ‰ç”¨æˆ·çš„ç­æ¬¡çŠ¶æ€"""
    logger.info("ğŸ”„ å¼€å§‹æ¢å¤ç”¨æˆ·ç­æ¬¡çŠ¶æ€...")
    recovered_count = 0

    try:
        all_groups = await db.get_all_groups()

        for chat_id in all_groups:
            try:
                if not await db.is_dual_mode_enabled(chat_id):
                    continue

                if not db.pool or not db._initialized:
                    logger.error("æ•°æ®åº“è¿æ¥æ± æœªåˆå§‹åŒ–")
                    return
                async with db.pool.acquire() as conn:
                    rows = await conn.fetch(
                        """
                        SELECT 
                            wr.user_id, 
                            wr.shift, 
                            wr.record_date,
                            MIN(wr.created_at) as earliest_time
                        FROM work_records wr
                        WHERE wr.chat_id = $1
                          AND wr.checkin_type = 'work_start'
                          AND NOT EXISTS (
                              SELECT 1 FROM work_records wr2
                              WHERE wr2.chat_id = wr.chat_id
                                AND wr2.user_id = wr.user_id
                                AND wr2.record_date = wr.record_date
                                AND wr2.shift = wr.shift
                                AND wr2.checkin_type = 'work_end'
                          )
                        GROUP BY wr.user_id, wr.shift, wr.record_date
                        """,
                        chat_id,
                    )

                    for row in rows:
                        await db.set_user_shift_state(
                            chat_id=chat_id,
                            user_id=row["user_id"],
                            shift=row["shift"],
                            record_date=row["record_date"],
                        )
                        recovered_count += 1
                        logger.info(
                            f"âœ… æ¢å¤ç”¨æˆ·ç­æ¬¡çŠ¶æ€: ç¾¤ç»„={chat_id}, "
                            f"ç”¨æˆ·={row['user_id']}, ç­æ¬¡={row['shift']}"
                        )

            except Exception as e:
                logger.error(f"âŒ æ¢å¤ç¾¤ç»„ {chat_id} ç­æ¬¡çŠ¶æ€å¤±è´¥: {e}")

        logger.info(f"âœ… ç”¨æˆ·ç­æ¬¡çŠ¶æ€æ¢å¤å®Œæˆï¼Œå…±æ¢å¤ {recovered_count} ä¸ªç­æ¬¡")
        return recovered_count

    except Exception as e:
        logger.error(f"âŒ ç”¨æˆ·ç­æ¬¡çŠ¶æ€æ¢å¤è¿‡ç¨‹å¤±è´¥: {e}")
        return 0
