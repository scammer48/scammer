import logging
import asyncio
import time
from datetime import datetime, timedelta, date
from typing import Dict, Any, List, Optional, Union
from config import Config, beijing_tz
import asyncpg
from asyncpg.pool import Pool

logger = logging.getLogger("GroupCheckInBot")


class PostgreSQLDatabase:
    """PostgreSQLæ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self, database_url: str = None):
        self.database_url = database_url or Config.DATABASE_URL
        self.pool: Optional[Pool] = None
        self._initialized = False
        self._cache = {}
        self._cache_ttl = {}

        # é‡è¿ç›¸å…³å±æ€§
        self._last_connection_check = 0
        self._connection_check_interval = 30
        self._reconnect_attempts = 0
        self._max_reconnect_attempts = 5
        self._reconnect_base_delay = 1.0

        self._maintenance_running = False
        self._maintenance_task = None
        self._connection_maintenance_task = None

        self._cache_max_size = 10000
        self._cache_access_order = []

    # ========== é‡è¿æœºåˆ¶ ==========
    async def _ensure_healthy_connection(self):
        """ç¡®ä¿è¿æ¥å¥åº·"""
        current_time = time.time()
        if current_time - self._last_connection_check < self._connection_check_interval:
            return True

        try:
            is_healthy = await self.connection_health_check()
            if not is_healthy:
                logger.warning("æ•°æ®åº“è¿æ¥ä¸å¥åº·ï¼Œå°è¯•é‡è¿...")
                await self._reconnect()

            self._last_connection_check = current_time
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def _reconnect(self):
        """é‡æ–°å»ºç«‹æ•°æ®åº“è¿æ¥"""
        self._reconnect_attempts += 1

        if self._reconnect_attempts > self._max_reconnect_attempts:
            logger.error(
                f"æ•°æ®åº“é‡è¿å°è¯•æ¬¡æ•°è¶…è¿‡ä¸Šé™ ({self._max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿"
            )
            raise ConnectionError("æ•°æ®åº“é‡è¿å¤±è´¥")

        try:
            delay = self._reconnect_base_delay * (
                2 ** (self._reconnect_attempts - 1)
            )  # æŒ‡æ•°é€€é¿
            logger.info(f"{delay}ç§’åå°è¯•ç¬¬{self._reconnect_attempts}æ¬¡æ•°æ®åº“é‡è¿...")
            await asyncio.sleep(delay)

            # å…³é—­æ—§è¿æ¥
            if self.pool:
                await self.pool.close()

            # é‡æ–°åˆå§‹åŒ–
            self.pool = None
            self._initialized = False
            await self._initialize_impl()

            # é‡ç½®é‡è¿è®¡æ•°
            self._reconnect_attempts = 0
            logger.info("âœ… æ•°æ®åº“é‡è¿æˆåŠŸ")

        except Exception as e:
            logger.error(f"æ•°æ®åº“ç¬¬{self._reconnect_attempts}æ¬¡é‡è¿å¤±è´¥: {e}")
            if self._reconnect_attempts >= self._max_reconnect_attempts:
                logger.critical("æ•°æ®åº“é‡è¿æœ€ç»ˆå¤±è´¥ï¼ŒæœåŠ¡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
            raise

    async def execute_with_retry(
        self, operation_name: str, query: str, *args, max_retries: int = 2
    ):
        """å¸¦é‡è¯•çš„æŸ¥è¯¢æ‰§è¡Œ"""
        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿è¿æ¥å¥åº·
                if not await self._ensure_healthy_connection():
                    raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                async with self.pool.acquire() as conn:
                    return await conn.execute(query, *args)

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"{operation_name} æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
                raise

    async def fetch_with_retry(
        self, operation_name: str, query: str, *args, max_retries: int = 2
    ):
        """å¸¦é‡è¯•çš„æŸ¥è¯¢è·å–"""
        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿è¿æ¥å¥åº·
                if not await self._ensure_healthy_connection():
                    raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                async with self.pool.acquire() as conn:
                    return await conn.fetch(query, *args)

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"{operation_name} æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                raise

    async def fetchrow_with_retry(
        self, operation_name: str, query: str, *args, max_retries: int = 2
    ):
        """å¸¦é‡è¯•çš„å•è¡ŒæŸ¥è¯¢"""
        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿è¿æ¥å¥åº·
                if not await self._ensure_healthy_connection():
                    raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                async with self.pool.acquire() as conn:
                    return await conn.fetchrow(query, *args)

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"{operation_name} æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                raise

    # ========== å®šæœŸç»´æŠ¤ä»»åŠ¡ ==========
    async def start_connection_maintenance(self):
        """å¯åŠ¨è¿æ¥ç»´æŠ¤ä»»åŠ¡"""
        if hasattr(self, "_maintenance_running") and self._maintenance_running:
            logger.info("è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return

        self._maintenance_running = True
        self._maintenance_task = asyncio.create_task(
            self._connection_maintenance_loop()
        )
        logger.info("âœ… æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²å¯åŠ¨")

    async def stop_connection_maintenance(self):
        """åœæ­¢è¿æ¥ç»´æŠ¤ä»»åŠ¡"""
        self._maintenance_running = False
        if hasattr(self, "_maintenance_task") and self._maintenance_task:
            self._maintenance_task.cancel()
            try:
                await self._maintenance_task
            except asyncio.CancelledError:
                pass
            self._maintenance_task = None
        logger.info("æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²åœæ­¢")

    async def _connection_maintenance_loop(self):
        """è¿æ¥ç»´æŠ¤å¾ªç¯"""
        logger.info("å¼€å§‹æ•°æ®åº“è¿æ¥ç»´æŠ¤å¾ªç¯...")

        while self._maintenance_running:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

                # æ‰§è¡Œè¿æ¥å¥åº·æ£€æŸ¥
                if not await self._ensure_healthy_connection():
                    logger.warning("è¿æ¥ç»´æŠ¤: æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                # æ¸…ç†è¿‡æœŸç¼“å­˜
                await self.cleanup_cache()

                # å®šæœŸæ¸…ç†æœˆåº¦æ•°æ®ï¼ˆå¯é€‰ï¼‰
                current_time = time.time()
                if current_time % 3600 < 60:  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
                    try:
                        await self.cleanup_old_data(days=Config.DATA_RETENTION_DAYS)
                        logger.debug("å®šæœŸæ•°æ®æ¸…ç†å®Œæˆ")
                    except Exception as e:
                        logger.error(f"å®šæœŸæ•°æ®æ¸…ç†å¤±è´¥: {e}")

            except asyncio.CancelledError:
                logger.info("æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"è¿æ¥ç»´æŠ¤ä»»åŠ¡å¼‚å¸¸: {e}")
                await asyncio.sleep(30)  # å¼‚å¸¸åç­‰å¾…30ç§’å†ç»§ç»­

    # ========== æ—¶åŒºç›¸å…³æ–¹æ³• ==========
    def get_beijing_time(self):
        """è·å–åŒ—äº¬æ—¶é—´"""
        return datetime.now(beijing_tz)

    def get_beijing_date(self):
        """è·å–åŒ—äº¬æ—¥æœŸ"""
        return self.get_beijing_time().date()

    # ========== åˆå§‹åŒ–æ–¹æ³• ==========
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if self._initialized:
            return

        max_retries = 5
        for attempt in range(max_retries):
            try:
                logger.info(f"è¿æ¥PostgreSQLæ•°æ®åº“ (å°è¯• {attempt + 1}/{max_retries})")
                await self._initialize_impl()
                logger.info("PostgreSQLæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
                self._initialized = True
                return
            except Exception as e:
                logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–ç¬¬ {attempt + 1} æ¬¡å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    logger.error(f"æ•°æ®åº“åˆå§‹åŒ–é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}")
                    # å°è¯•å¼ºåˆ¶é‡å»ºè¡¨
                    try:
                        await self._force_recreate_tables()
                        self._initialized = True
                        logger.info("âœ… æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºæˆåŠŸ")
                        return
                    except Exception as rebuild_error:
                        logger.error(f"æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºå¤±è´¥: {rebuild_error}")
                        raise e
                await asyncio.sleep(2**attempt)

    async def _initialize_impl(self):
        """å®é™…çš„æ•°æ®åº“åˆå§‹åŒ–å®ç°"""
        self.pool = await asyncpg.create_pool(
            self.database_url,
            min_size=Config.DB_MIN_CONNECTIONS,
            max_size=Config.DB_MAX_CONNECTIONS,
            max_inactive_connection_lifetime=Config.DB_POOL_RECYCLE,
            command_timeout=Config.DB_CONNECTION_TIMEOUT,
            timeout=60,
        )
        logger.info("PostgreSQLè¿æ¥æ± åˆ›å»ºæˆåŠŸ")

        async with self.pool.acquire() as conn:
            await conn.execute("SET statement_timeout = 30000")
            await conn.execute("SET idle_in_transaction_session_timeout = 60000")

        # åˆ›å»ºè¡¨å’Œç´¢å¼• - æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                await self._create_tables()
                await self._create_indexes()
                await self._initialize_default_data()
                logger.info("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
                break
            except Exception as e:
                logger.warning(f"æ•°æ®åº“è¡¨åˆå§‹åŒ–ç¬¬ {attempt + 1} æ¬¡å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    logger.error("æ•°æ®åº“è¡¨åˆå§‹åŒ–æœ€ç»ˆå¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡å»º...")
                    await self._force_recreate_tables()
                await asyncio.sleep(1)

    async def _force_recreate_tables(self):
        """å¼ºåˆ¶é‡æ–°åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆç”¨äºä¿®å¤æŸåçš„æ•°æ®åº“ï¼‰"""
        logger.warning("ğŸ”„ å¼ºåˆ¶é‡æ–°åˆ›å»ºæ•°æ®åº“è¡¨...")

        async with self.pool.acquire() as conn:
            # åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆæŒ‰ä¾èµ–é¡ºåºï¼‰
            tables = [
                "monthly_statistics",
                "activity_user_limits",
                "push_settings",
                "work_fine_configs",
                "fine_configs",
                "activity_configs",
                "work_records",
                "user_activities",
                "users",
                "groups",
            ]

            for table in tables:
                try:
                    await conn.execute(f"DROP TABLE IF EXISTS {table} CASCADE")
                    logger.info(f"âœ… åˆ é™¤è¡¨: {table}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤è¡¨ {table} å¤±è´¥: {e}")

            # é‡æ–°åˆ›å»ºè¡¨
            await self._create_tables()
            await self._create_indexes()
            await self._initialize_default_data()
            logger.info("ğŸ‰ æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºå®Œæˆ")

    def _extract_table_name(self, table_sql: str) -> str:
        """å®‰å…¨æå–è¡¨å"""
        try:
            # ä½¿ç”¨æ›´ç¨³å®šçš„æ–¹å¼æå–è¡¨å
            words = table_sql.upper().split()
            if "TABLE" in words:
                table_index = words.index("TABLE") + 1
                if table_index < len(words) and words[table_index] == "IF":
                    table_index += 3  # è·³è¿‡ IF NOT EXISTS
                elif table_index < len(words) and words[table_index] == "NOT":
                    table_index += 2  # è·³è¿‡ NOT EXISTS
                return words[table_index] if table_index < len(words) else "unknown"
        except Exception:
            pass
        return "unknown"

    async def _create_tables(self):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„è¡¨"""
        async with self.pool.acquire() as conn:
            tables = [
                # groupsè¡¨
                """
                CREATE TABLE IF NOT EXISTS groups (
                    chat_id BIGINT PRIMARY KEY,
                    channel_id BIGINT,
                    notification_group_id BIGINT,
                    reset_hour INTEGER DEFAULT 0,
                    reset_minute INTEGER DEFAULT 0,
                    work_start_time TEXT DEFAULT '09:00',
                    work_end_time TEXT DEFAULT '18:00',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # usersè¡¨
                """
                CREATE TABLE IF NOT EXISTS users (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT NOT NULL,
                    user_id BIGINT NOT NULL,
                    nickname TEXT,
                    current_activity TEXT,
                    activity_start_time TEXT,
                    total_accumulated_time INTEGER DEFAULT 0,
                    total_activity_count INTEGER DEFAULT 0,
                    total_fines INTEGER DEFAULT 0,
                    overtime_count INTEGER DEFAULT 0,
                    total_overtime_time INTEGER DEFAULT 0,
                    last_updated DATE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id)
                )
                """,
                # user_activitiesè¡¨
                """
                CREATE TABLE IF NOT EXISTS user_activities (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    activity_date DATE,
                    activity_name TEXT,
                    activity_count INTEGER DEFAULT 0,
                    accumulated_time INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, activity_date, activity_name)
                )
                """,
                # work_recordsè¡¨
                """
                CREATE TABLE IF NOT EXISTS work_records (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    record_date DATE,
                    checkin_type TEXT,
                    checkin_time TEXT,
                    status TEXT,
                    time_diff_minutes REAL,
                    fine_amount INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, record_date, checkin_type)
                )
                """,
                # activity_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS activity_configs (
                    activity_name TEXT PRIMARY KEY,
                    max_times INTEGER,
                    time_limit INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # fine_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS fine_configs (
                    id SERIAL PRIMARY KEY,
                    activity_name TEXT,
                    time_segment TEXT,
                    fine_amount INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(activity_name, time_segment)
                )
                """,
                # work_fine_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS work_fine_configs (
                    id SERIAL PRIMARY KEY,
                    checkin_type TEXT,
                    time_segment TEXT,
                    fine_amount INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(checkin_type, time_segment)
                )
                """,
                # push_settingsè¡¨
                """
                CREATE TABLE IF NOT EXISTS push_settings (
                    setting_key TEXT PRIMARY KEY,
                    setting_value INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # monthly_statisticsè¡¨
                """
                CREATE TABLE IF NOT EXISTS monthly_statistics (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    statistic_date DATE,
                    activity_name TEXT,
                    activity_count INTEGER DEFAULT 0,
                    accumulated_time INTEGER DEFAULT 0,
                    work_days INTEGER DEFAULT 0,
                    work_hours INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, statistic_date, activity_name)
                )
                """,
                # activity_user_limitsè¡¨
                """
                CREATE TABLE IF NOT EXISTS activity_user_limits (
                    activity_name TEXT PRIMARY KEY,
                    max_users INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
            ]

            for table_sql in tables:
                try:
                    await conn.execute(table_sql)
                    table_name = self._extract_table_name(table_sql)
                    logger.info(f"âœ… åˆ›å»ºè¡¨: {table_name}")
                except Exception as e:
                    logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
                    # è®°å½•å¤±è´¥çš„SQLç”¨äºè°ƒè¯•
                    logger.error(f"å¤±è´¥çš„SQL: {table_sql[:100]}...")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
            logger.info("æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")

    async def _create_indexes(self):
        """åˆ›å»ºæ€§èƒ½ç´¢å¼•"""
        async with self.pool.acquire() as conn:
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_user_activities_main ON user_activities (chat_id, user_id, activity_date)",
                "CREATE INDEX IF NOT EXISTS idx_work_records_main ON work_records (chat_id, user_id, record_date)",
                "CREATE INDEX IF NOT EXISTS idx_users_main ON users (chat_id, user_id)",
                "CREATE INDEX IF NOT EXISTS idx_monthly_stats_main ON monthly_statistics (chat_id, user_id, statistic_date)",
            ]

            for index_sql in indexes:
                try:
                    await conn.execute(index_sql)
                    index_name = index_sql.split()[5]  # è·å–ç´¢å¼•å
                    logger.info(f"âœ… åˆ›å»ºç´¢å¼•: {index_name}")
                except Exception as e:
                    logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
                    # ç´¢å¼•åˆ›å»ºå¤±è´¥ä¸é˜»æ­¢ç¨‹åºå¯åŠ¨
            logger.info("æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")

    async def _initialize_default_data(self):
        """åˆå§‹åŒ–é»˜è®¤æ•°æ®"""
        async with self.pool.acquire() as conn:
            # åˆå§‹åŒ–æ´»åŠ¨é…ç½®
            for activity, limits in Config.DEFAULT_ACTIVITY_LIMITS.items():
                await conn.execute(
                    "INSERT INTO activity_configs (activity_name, max_times, time_limit) VALUES ($1, $2, $3) ON CONFLICT (activity_name) DO NOTHING",
                    activity,
                    limits["max_times"],
                    limits["time_limit"],
                )
                logger.info(f"âœ… åˆå§‹åŒ–æ´»åŠ¨é…ç½®: {activity}")

            # åˆå§‹åŒ–ç½šæ¬¾é…ç½®
            for activity, fines in Config.DEFAULT_FINE_RATES.items():
                for time_segment, amount in fines.items():
                    await conn.execute(
                        "INSERT INTO fine_configs (activity_name, time_segment, fine_amount) VALUES ($1, $2, $3) ON CONFLICT (activity_name, time_segment) DO NOTHING",
                        activity,
                        time_segment,
                        amount,
                    )
                logger.info(f"âœ… åˆå§‹åŒ–ç½šæ¬¾é…ç½®: {activity}")

            # åˆå§‹åŒ–æ¨é€è®¾ç½®
            for key, value in Config.AUTO_EXPORT_SETTINGS.items():
                await conn.execute(
                    "INSERT INTO push_settings (setting_key, setting_value) VALUES ($1, $2) ON CONFLICT (setting_key) DO NOTHING",
                    key,
                    1 if value else 0,
                )
                logger.info(f"âœ… åˆå§‹åŒ–æ¨é€è®¾ç½®: {key}")

            logger.info("é»˜è®¤æ•°æ®åˆå§‹åŒ–å®Œæˆ")

    async def health_check(self) -> bool:
        """å®Œæ•´çš„æ•°æ®åº“å¥åº·æ£€æŸ¥ - å¢å¼ºç‰ˆ"""
        if not self.pool or not self._initialized:
            logger.warning("æ•°æ®åº“æœªåˆå§‹åŒ–")
            return False

        try:
            async with self.pool.acquire() as conn:
                # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                result = await conn.fetchval("SELECT 1")
                if result != 1:
                    return False

                # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨ä¸”å¯è®¿é—®
                critical_tables = ["users", "groups", "activity_configs"]
                for table in critical_tables:
                    try:
                        await conn.fetchval(f"SELECT 1 FROM {table} LIMIT 1")
                    except Exception as e:
                        logger.error(f"âŒ å…³é”®è¡¨ {table} è®¿é—®å¤±è´¥: {e}")
                        return False

                return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    # ========== è¿æ¥ç®¡ç† ==========
    def _ensure_pool_initialized(self):
        """ç¡®ä¿è¿æ¥æ± å·²åˆå§‹åŒ–"""
        if not self.pool or not self._initialized:
            raise RuntimeError("æ•°æ®åº“è¿æ¥æ± å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize() æ–¹æ³•")

    async def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        self._ensure_pool_initialized()
        return await self.pool.acquire()

    async def release_connection(self, conn):
        """é‡Šæ”¾æ•°æ®åº“è¿æ¥"""
        if self.pool:
            await self.pool.release(conn)

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        try:
            if self.pool:
                await self.pool.close()
                logger.info("PostgreSQLè¿æ¥æ± å·²å…³é—­")
        except Exception as e:
            logger.warning(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºç°å¼‚å¸¸: {e}")

    # ========== ç¼“å­˜ç®¡ç† ==========
    def _get_cached(self, key: str):
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self._cache_ttl and time.time() < self._cache_ttl[key]:
            return self._cache.get(key)
        else:
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            if key in self._cache:
                del self._cache[key]
            if key in self._cache_ttl:
                del self._cache_ttl[key]
            return None

    def _set_cached(self, key: str, value: Any, ttl: int = 60):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self._cache[key] = value
        self._cache_ttl[key] = time.time() + ttl

    async def cleanup_cache(self):
        """ğŸ†• å¢å¼ºçš„ç¼“å­˜æ¸…ç† - è¿‡æœŸæ¸…ç† + LRUæ¸…ç†"""
        current_time = time.time()
        expired_keys = [
            key for key, expiry in self._cache_ttl.items() if current_time >= expiry
        ]

        for key in expired_keys:
            self._cache.pop(key, None)
            self._cache_ttl.pop(key, None)
            if key in self._cache_access_order:
                self._cache_access_order.remove(key)

        # ğŸ†• é¢å¤–æ¸…ç†ï¼šå¦‚æœç¼“å­˜ä»ç„¶è¿‡å¤§ï¼Œç§»é™¤æœ€æ—§çš„ä¸€äº›æ¡ç›®
        if len(self._cache) > self._cache_max_size * 0.8:  # 80%é˜ˆå€¼
            excess = len(self._cache) - int(self._cache_max_size * 0.7)  # æ¸…ç†åˆ°70%
            if excess > 0 and self._cache_access_order:
                keys_to_remove = self._cache_access_order[:excess]
                for key in keys_to_remove:
                    self._cache.pop(key, None)
                    self._cache_ttl.pop(key, None)
                self._cache_access_order = self._cache_access_order[excess:]
                logger.info(f"LRUå¼ºåˆ¶æ¸…ç†: ç§»é™¤äº† {len(keys_to_remove)} ä¸ªæ—§ç¼“å­˜")

        if expired_keys:
            logger.debug(
                f"ç¼“å­˜æ¸…ç†å®Œæˆ: {len(expired_keys)}ä¸ªè¿‡æœŸ, å½“å‰å¤§å°: {len(self._cache)}"
            )

    async def force_refresh_activity_cache(self):
        """å¼ºåˆ¶åˆ·æ–°æ´»åŠ¨é…ç½®ç¼“å­˜"""
        cache_keys_to_remove = ["activity_limits", "push_settings", "fine_rates"]
        for key in cache_keys_to_remove:
            self._cache.pop(key, None)
            self._cache_ttl.pop(key, None)
        await self.get_activity_limits()
        await self.get_fine_rates()
        logger.info("æ´»åŠ¨é…ç½®ç¼“å­˜å·²å¼ºåˆ¶åˆ·æ–°")

    # ========== ç¾¤ç»„ç›¸å…³æ“ä½œ ==========
    async def init_group(self, chat_id: int):
        """åˆå§‹åŒ–ç¾¤ç»„ - å¸¦é‡è¯•"""
        await self.execute_with_retry(
            "åˆå§‹åŒ–ç¾¤ç»„",
            "INSERT INTO groups (chat_id) VALUES ($1) ON CONFLICT (chat_id) DO NOTHING",
            chat_id,
        )
        self._cache.pop(f"group:{chat_id}", None)

    async def get_group(self, chat_id: int) -> Optional[Dict]:
        """è·å–ç¾¤ç»„é…ç½®"""
        cache_key = f"group:{chat_id}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT * FROM groups WHERE chat_id = $1", chat_id
            )
            if row:
                result = dict(row)
                self._set_cached(cache_key, result, 300)
                return result
            return None

    async def get_group_cached(self, chat_id: int) -> Optional[Dict]:
        """å¸¦ç¼“å­˜çš„è·å–ç¾¤ç»„é…ç½®"""
        return await self.get_group(chat_id)

    async def update_group_channel(self, chat_id: int, channel_id: int):
        """æ›´æ–°ç¾¤ç»„é¢‘é“ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET channel_id = $1, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $2",
                channel_id,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def update_group_notification(self, chat_id: int, group_id: int):
        """æ›´æ–°ç¾¤ç»„é€šçŸ¥ç¾¤ç»„ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET notification_group_id = $1, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $2",
                group_id,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def update_group_reset_time(self, chat_id: int, hour: int, minute: int):
        """æ›´æ–°ç¾¤ç»„é‡ç½®æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET reset_hour = $1, reset_minute = $2, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $3",
                hour,
                minute,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def update_group_work_time(
        self, chat_id: int, work_start: str, work_end: str
    ):
        """æ›´æ–°ç¾¤ç»„ä¸Šä¸‹ç­æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET work_start_time = $1, work_end_time = $2, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $3",
                work_start,
                work_end,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def get_group_work_time(self, chat_id: int) -> Dict[str, str]:
        """è·å–ç¾¤ç»„ä¸Šä¸‹ç­æ—¶é—´ - å¸¦é‡è¯•"""
        row = await self.fetchrow_with_retry(
            "è·å–å·¥ä½œæ—¶é—´",
            "SELECT work_start_time, work_end_time FROM groups WHERE chat_id = $1",
            chat_id,
        )
        if row and row["work_start_time"] and row["work_end_time"]:
            return {
                "work_start": row["work_start_time"],
                "work_end": row["work_end_time"],
            }
        return Config.DEFAULT_WORK_HOURS.copy()

    async def has_work_hours_enabled(self, chat_id: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†ä¸Šä¸‹ç­åŠŸèƒ½"""
        work_hours = await self.get_group_work_time(chat_id)
        return (
            work_hours["work_start"] != Config.DEFAULT_WORK_HOURS["work_start"]
            or work_hours["work_end"] != Config.DEFAULT_WORK_HOURS["work_end"]
        )

    # ========== ç”¨æˆ·ç›¸å…³æ“ä½œ ==========
    async def init_user(self, chat_id: int, user_id: int, nickname: str = None):
        """åˆå§‹åŒ–ç”¨æˆ· - å¸¦é‡è¯•"""
        today = self.get_beijing_date()
        await self.execute_with_retry(
            "åˆå§‹åŒ–ç”¨æˆ·",
            """
            INSERT INTO users (chat_id, user_id, nickname, last_updated) 
            VALUES ($1, $2, $3, $4) 
            ON CONFLICT (chat_id, user_id) 
            DO UPDATE SET 
                nickname = COALESCE($3, users.nickname),
                last_updated = $4,
                updated_at = CURRENT_TIMESTAMP
            """,
            chat_id,
            user_id,
            nickname,
            today,
        )
        self._cache.pop(f"user:{chat_id}:{user_id}", None)

    async def update_user_last_updated(
        self, chat_id: int, user_id: int, update_date: date
    ):
        """æ›´æ–°ç”¨æˆ·æœ€åæ›´æ–°æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE users SET last_updated = $1 WHERE chat_id = $2 AND user_id = $3",
                update_date,
                chat_id,
                user_id,
            )

    async def get_user(self, chat_id: int, user_id: int) -> Optional[Dict]:
        """è·å–ç”¨æˆ·æ•°æ® - å¸¦é‡è¯•"""
        cache_key = f"user:{chat_id}:{user_id}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        row = await self.fetchrow_with_retry(
            "è·å–ç”¨æˆ·æ•°æ®",
            "SELECT * FROM users WHERE chat_id = $1 AND user_id = $2",
            chat_id,
            user_id,
        )

        if row:
            result = dict(row)
            self._set_cached(cache_key, result, 30)
            return result
        return None

    async def get_user_cached(self, chat_id: int, user_id: int) -> Optional[Dict]:
        """å¸¦ç¼“å­˜çš„è·å–ç”¨æˆ·æ•°æ®"""
        return await self.get_user(chat_id, user_id)

    async def update_user_activity(
        self,
        chat_id: int,
        user_id: int,
        activity: str,
        start_time: str,
        nickname: str = None,
    ):
        """æ›´æ–°ç”¨æˆ·æ´»åŠ¨çŠ¶æ€ - å¸¦é‡è¯•"""
        if nickname:
            await self.execute_with_retry(
                "æ›´æ–°ç”¨æˆ·æ´»åŠ¨",
                """
                UPDATE users SET current_activity = $1, activity_start_time = $2, nickname = $3, updated_at = CURRENT_TIMESTAMP 
                WHERE chat_id = $4 AND user_id = $5
                """,
                activity,
                start_time,
                nickname,
                chat_id,
                user_id,
            )
        else:
            await self.execute_with_retry(
                "æ›´æ–°ç”¨æˆ·æ´»åŠ¨",
                """
                UPDATE users SET current_activity = $1, activity_start_time = $2, updated_at = CURRENT_TIMESTAMP 
                WHERE chat_id = $3 AND user_id = $4
                """,
                activity,
                start_time,
                chat_id,
                user_id,
            )
        self._cache.pop(f"user:{chat_id}:{user_id}", None)

    async def complete_user_activity(
        self,
        chat_id: int,
        user_id: int,
        activity: str,
        elapsed_time: int,
        fine_amount: int = 0,
        is_overtime: bool = False,
    ):
        """å®Œæˆç”¨æˆ·æ´»åŠ¨ - ä¿®å¤ç‰ˆ"""
        today = self.get_beijing_date()
        statistic_date = today.replace(day=1)

        # ğŸ†• è®¡ç®—è¶…æ—¶ç›¸å…³æ•°æ®
        overtime_seconds = 0
        if is_overtime:
            time_limit = await self.get_activity_time_limit(activity)
            time_limit_seconds = time_limit * 60
            overtime_seconds = max(0, elapsed_time - time_limit_seconds)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                # æ›´æ–°ç”¨æˆ·è¡¨
                await conn.execute(
                    """
                    INSERT INTO users (chat_id, user_id, last_updated) 
                    VALUES ($1, $2, $3)
                    ON CONFLICT (chat_id, user_id) 
                    DO UPDATE SET last_updated = EXCLUDED.last_updated
                    """,
                    chat_id,
                    user_id,
                    today,
                )

                # æ›´æ–°user_activitiesè¡¨
                await conn.execute(
                    """
                    INSERT INTO user_activities 
                    (chat_id, user_id, activity_date, activity_name, activity_count, accumulated_time)
                    VALUES ($1, $2, $3, $4, 1, $5)
                    ON CONFLICT (chat_id, user_id, activity_date, activity_name) 
                    DO UPDATE SET 
                        activity_count = user_activities.activity_count + 1,
                        accumulated_time = user_activities.accumulated_time + EXCLUDED.accumulated_time,
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    chat_id,
                    user_id,
                    today,
                    activity,
                    elapsed_time,
                )

                # æ›´æ–°æœˆåº¦ç»Ÿè®¡è¡¨ - æ´»åŠ¨æ•°æ®
                await conn.execute(
                    """
                    INSERT INTO monthly_statistics 
                    (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                    VALUES ($1, $2, $3, $4, 1, $5)
                    ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                    DO UPDATE SET 
                        activity_count = monthly_statistics.activity_count + 1,
                        accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    chat_id,
                    user_id,
                    statistic_date,
                    activity,
                    elapsed_time,
                )

                # ğŸ†• ä¿®å¤ï¼šå°†è¶…æ—¶æ•°æ®å†™å…¥æœˆåº¦ç»Ÿè®¡è¡¨
                if is_overtime and overtime_seconds > 0:
                    # æ›´æ–°è¶…æ—¶æ¬¡æ•°åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                    await conn.execute(
                        """
                        INSERT INTO monthly_statistics 
                        (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                        VALUES ($1, $2, $3, 'overtime_count', 1, 0)
                        ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                        DO UPDATE SET 
                            activity_count = monthly_statistics.activity_count + 1,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        chat_id,
                        user_id,
                        statistic_date,
                    )

                    # æ›´æ–°è¶…æ—¶æ—¶é—´åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                    await conn.execute(
                        """
                        INSERT INTO monthly_statistics 
                        (chat_id, user_id, statistic_date, activity_name, accumulated_time, activity_count)
                        VALUES ($1, $2, $3, 'overtime_time', $4, 0)
                        ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                        DO UPDATE SET 
                            accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        chat_id,
                        user_id,
                        statistic_date,
                        overtime_seconds,
                    )

                # æ›´æ–°ç½šæ¬¾ç»Ÿè®¡
                if fine_amount > 0:
                    await conn.execute(
                        """
                        INSERT INTO monthly_statistics 
                        (chat_id, user_id, statistic_date, activity_name, accumulated_time)
                        VALUES ($1, $2, $3, 'total_fines', $4)
                        ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                        DO UPDATE SET 
                            accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        chat_id,
                        user_id,
                        statistic_date,
                        fine_amount,
                    )

                # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
                update_fields = [
                    "total_accumulated_time = total_accumulated_time + $1",
                    "total_activity_count = total_activity_count + 1",
                    "current_activity = NULL",
                    "activity_start_time = NULL",
                    "last_updated = $2",
                ]
                params = [elapsed_time, today]

                if fine_amount > 0:
                    update_fields.append("total_fines = total_fines + $3")
                    params.append(fine_amount)

                if is_overtime:
                    update_fields.append("overtime_count = overtime_count + 1")
                    update_fields.append(
                        "total_overtime_time = total_overtime_time + $4"
                    )
                    params.append(overtime_seconds)

                update_fields.append("updated_at = CURRENT_TIMESTAMP")
                params.extend([chat_id, user_id])

                placeholders = ", ".join(update_fields)
                query = f"UPDATE users SET {placeholders} WHERE chat_id = ${len(params)-1} AND user_id = ${len(params)}"
                await conn.execute(query, *params)

            self._cache.pop(f"user:{chat_id}:{user_id}", None)

    async def reset_user_daily_data(
        self, chat_id: int, user_id: int, target_date: Optional[date] = None
    ):
        """é‡ç½®ç”¨æˆ·æ¯æ—¥æ•°æ®"""
        try:
            if target_date is None:
                target_date = self.get_beijing_date()

            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                async with conn.transaction():
                    # åˆ é™¤æ´»åŠ¨è®°å½•
                    await conn.execute(
                        "DELETE FROM user_activities WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3",
                        chat_id,
                        user_id,
                        target_date,
                    )

                    # é‡ç½®ç”¨æˆ·æ•°æ®
                    await conn.execute(
                        """
                        UPDATE users SET
                            total_activity_count = 0,
                            total_accumulated_time = 0,
                            total_fines = 0,
                            total_overtime_time = 0,
                            overtime_count = 0,
                            current_activity = NULL,
                            activity_start_time = NULL,
                            last_updated = $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE chat_id = $1 AND user_id = $2
                        """,
                        chat_id,
                        user_id,
                        target_date,
                    )

            # æ¸…ç†ç¼“å­˜
            cache_keys = [f"user:{chat_id}:{user_id}", f"group:{chat_id}"]
            for key in cache_keys:
                self._cache.pop(key, None)

            logger.info(f"ç”¨æˆ·æ•°æ®é‡ç½®å®Œæˆ: {chat_id}-{user_id}")
            return True

        except Exception as e:
            logger.error(f"é‡ç½®ç”¨æˆ·æ•°æ®å¤±è´¥ {chat_id}-{user_id}: {e}")
            return False

    async def get_user_activity_count(
        self, chat_id: int, user_id: int, activity: str
    ) -> int:
        """è·å–ç”¨æˆ·ä»Šæ—¥æ´»åŠ¨æ¬¡æ•°"""
        today = self.get_beijing_date()
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT activity_count FROM user_activities WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3 AND activity_name = $4",
                chat_id,
                user_id,
                today,
                activity,
            )
            return row["activity_count"] if row else 0

    async def get_user_all_activities(
        self, chat_id: int, user_id: int
    ) -> Dict[str, Dict]:
        """è·å–ç”¨æˆ·æ‰€æœ‰æ´»åŠ¨æ•°æ®"""
        today = self.get_beijing_date()
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT activity_name, activity_count, accumulated_time FROM user_activities WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3",
                chat_id,
                user_id,
                today,
            )

            activities = {}
            for row in rows:
                activities[row["activity_name"]] = {
                    "count": row["activity_count"],
                    "time": row["accumulated_time"],
                }
            return activities

    # ========== ä¸Šä¸‹ç­è®°å½•æ“ä½œ ==========
    async def add_work_record(
        self,
        chat_id: int,
        user_id: int,
        record_date,
        checkin_type: str,
        checkin_time: str,
        status: str,
        time_diff_minutes: float,
        fine_amount: int = 0,
    ):
        """æ·»åŠ ä¸Šä¸‹ç­è®°å½• - ä¿®å¤ç‰ˆ"""
        if isinstance(record_date, str):
            record_date = datetime.strptime(record_date, "%Y-%m-%d").date()
        elif isinstance(record_date, datetime):
            record_date = record_date.date()

        statistic_date = record_date.replace(day=1)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                # æ·»åŠ ä¸Šä¸‹ç­è®°å½•
                await conn.execute(
                    """
                    INSERT INTO work_records 
                    (chat_id, user_id, record_date, checkin_type, checkin_time, status, time_diff_minutes, fine_amount)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                    ON CONFLICT (chat_id, user_id, record_date, checkin_type) 
                    DO UPDATE SET 
                        checkin_time = EXCLUDED.checkin_time,
                        status = EXCLUDED.status,
                        time_diff_minutes = EXCLUDED.time_diff_minutes,
                        fine_amount = EXCLUDED.fine_amount,
                        created_at = CURRENT_TIMESTAMP
                    """,
                    chat_id,
                    user_id,
                    record_date,
                    checkin_type,
                    checkin_time,
                    status,
                    time_diff_minutes,
                    fine_amount,
                )

                # ğŸ†• ä¿®å¤ï¼šå®Œæ•´çš„å·¥ä½œå¤©æ•°å’Œå·¥ä½œæ—¶é•¿ç»Ÿè®¡
                if checkin_type == "work_end":
                    # è·å–å¯¹åº”çš„ä¸Šç­è®°å½•
                    work_start_record = await conn.fetchrow(
                        "SELECT checkin_time FROM work_records WHERE chat_id = $1 AND user_id = $2 AND record_date = $3 AND checkin_type = 'work_start'",
                        chat_id,
                        user_id,
                        record_date,
                    )

                    if work_start_record:
                        try:
                            # è®¡ç®—å·¥ä½œæ—¶é•¿
                            start_time_str = work_start_record["checkin_time"]
                            end_time_str = checkin_time

                            # è§£ææ—¶é—´ï¼ˆæ ¼å¼ä¸º HH:MMï¼‰
                            start_time = datetime.strptime(start_time_str, "%H:%M")
                            end_time = datetime.strptime(end_time_str, "%H:%M")

                            # è®¡ç®—å·¥ä½œæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                            work_duration_minutes = (
                                end_time - start_time
                            ).total_seconds() / 60

                            # å¤„ç†è·¨å¤©æƒ…å†µï¼ˆå¦‚æœä¸‹ç­æ—¶é—´å°äºä¸Šç­æ—¶é—´ï¼Œè¯´æ˜è·¨å¤©äº†ï¼‰
                            if work_duration_minutes < 0:
                                work_duration_minutes += 24 * 60  # åŠ ä¸Š24å°æ—¶

                            # è½¬æ¢ä¸ºç§’
                            work_duration_seconds = int(work_duration_minutes * 60)

                            # ğŸ†• æ›´æ–°å·¥ä½œå¤©æ•°åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                                VALUES ($1, $2, $3, 'work_days', 1, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    activity_count = monthly_statistics.activity_count + 1,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                            )

                            # ğŸ†• æ›´æ–°å·¥ä½œæ—¶é•¿åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, accumulated_time, activity_count)
                                VALUES ($1, $2, $3, 'work_hours', $4, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                                work_duration_seconds,
                            )

                            logger.info(
                                f"å·¥ä½œç»Ÿè®¡æ›´æ–°: ç”¨æˆ·{user_id} å·¥ä½œæ—¶é•¿{work_duration_minutes:.1f}åˆ†é’Ÿ"
                            )

                        except Exception as e:
                            logger.error(f"è®¡ç®—å·¥ä½œæ—¶é•¿å¤±è´¥: {e}")
                            # å³ä½¿è®¡ç®—å¤±è´¥ï¼Œä¹Ÿè®°å½•å·¥ä½œå¤©æ•°ï¼ˆä½†ä¸è®°å½•æ—¶é•¿ï¼‰
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                                VALUES ($1, $2, $3, 'work_days', 1, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    activity_count = monthly_statistics.activity_count + 1,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                            )

                # æ›´æ–°ç½šæ¬¾ç»Ÿè®¡
                if fine_amount > 0:
                    await conn.execute(
                        "UPDATE users SET total_fines = total_fines + $1 WHERE chat_id = $2 AND user_id = $3",
                        fine_amount,
                        chat_id,
                        user_id,
                    )

            self._cache.pop(f"user:{chat_id}:{user_id}", None)

    async def has_work_record_today(
        self, chat_id: int, user_id: int, checkin_type: str
    ) -> bool:
        """æ£€æŸ¥ä»Šå¤©æ˜¯å¦æœ‰ä¸Šä¸‹ç­è®°å½• - ä¿®å¤ç‰ˆï¼šä½¿ç”¨é‡ç½®å‘¨æœŸ"""
        # è·å–é‡ç½®æ—¶é—´
        group_data = await self.get_group_cached(chat_id)
        reset_hour = group_data.get("reset_hour", Config.DAILY_RESET_HOUR)
        reset_minute = group_data.get("reset_minute", Config.DAILY_RESET_MINUTE)

        now = self.get_beijing_time()

        # è®¡ç®—å½“å‰é‡ç½®å‘¨æœŸå¼€å§‹æ—¶é—´ï¼ˆä¸reset_daily_data_if_neededä¿æŒä¸€è‡´ï¼‰
        reset_time_today = now.replace(
            hour=reset_hour, minute=reset_minute, second=0, microsecond=0
        )
        if now < reset_time_today:
            period_start = reset_time_today - timedelta(days=1)
        else:
            period_start = reset_time_today

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT 1 FROM work_records WHERE chat_id = $1 AND user_id = $2 AND checkin_type = $3 AND record_date >= $4",
                chat_id,
                user_id,
                checkin_type,
                period_start.date(),  # ä½¿ç”¨é‡ç½®å‘¨æœŸå¼€å§‹æ—¥æœŸ
            )
            return row is not None

    async def get_today_work_records(
        self, chat_id: int, user_id: int
    ) -> Dict[str, Dict]:
        """è·å–ç”¨æˆ·ä»Šå¤©çš„ä¸Šä¸‹ç­è®°å½• - ä¿®å¤ç‰ˆï¼šä½¿ç”¨é‡ç½®å‘¨æœŸ"""
        # è·å–é‡ç½®æ—¶é—´
        group_data = await self.get_group_cached(chat_id)
        reset_hour = group_data.get("reset_hour", Config.DAILY_RESET_HOUR)
        reset_minute = group_data.get("reset_minute", Config.DAILY_RESET_MINUTE)

        now = self.get_beijing_time()

        # è®¡ç®—å½“å‰é‡ç½®å‘¨æœŸå¼€å§‹æ—¶é—´
        reset_time_today = now.replace(
            hour=reset_hour, minute=reset_minute, second=0, microsecond=0
        )
        if now < reset_time_today:
            period_start = reset_time_today - timedelta(days=1)
        else:
            period_start = reset_time_today

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT * FROM work_records WHERE chat_id = $1 AND user_id = $2 AND record_date >= $3",
                chat_id,
                user_id,
                period_start.date(),  # ä½¿ç”¨é‡ç½®å‘¨æœŸå¼€å§‹æ—¥æœŸ
            )

            records = {}
            for row in rows:
                records[row["checkin_type"]] = dict(row)
            return records

    # ========== æ´»åŠ¨é…ç½®æ“ä½œ ==========
    async def get_activity_limits(self) -> Dict:
        """è·å–æ‰€æœ‰æ´»åŠ¨é™åˆ¶ - å¸¦é‡è¯•"""
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        if not self.pool or not self._initialized:
            logger.warning("æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜è®¤æ´»åŠ¨é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

        cache_key = "activity_limits"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        try:
            rows = await self.fetch_with_retry(
                "è·å–æ´»åŠ¨é™åˆ¶", "SELECT * FROM activity_configs"
            )
            limits = {
                row["activity_name"]: {
                    "max_times": row["max_times"],
                    "time_limit": row["time_limit"],
                }
                for row in rows
            }
            self._set_cached(cache_key, limits, 300)
            return limits
        except Exception as e:
            logger.error(f"è·å–æ´»åŠ¨é…ç½®å¤±è´¥: {e}ï¼Œè¿”å›é»˜è®¤é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

    async def get_activity_limits_cached(self) -> Dict:
        """å¸¦ç¼“å­˜çš„è·å–æ´»åŠ¨é™åˆ¶"""
        try:
            return await self.get_activity_limits()
        except Exception as e:
            logger.error(f"è·å–æ´»åŠ¨é…ç½®ç¼“å­˜å¤±è´¥: {e}ï¼Œè¿”å›é»˜è®¤é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

    async def get_activity_time_limit(self, activity: str) -> int:
        """è·å–æ´»åŠ¨æ—¶é—´é™åˆ¶"""
        limits = await self.get_activity_limits()
        return limits.get(activity, {}).get("time_limit", 0)

    async def get_activity_max_times(self, activity: str) -> int:
        """è·å–æ´»åŠ¨æœ€å¤§æ¬¡æ•°"""
        limits = await self.get_activity_limits()
        return limits.get(activity, {}).get("max_times", 0)

    async def activity_exists(self, activity: str) -> bool:
        """æ£€æŸ¥æ´»åŠ¨æ˜¯å¦å­˜åœ¨"""
        cache_key = "activity_limits"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return activity in cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT 1 FROM activity_configs WHERE activity_name = $1", activity
            )
            return row is not None

    async def update_activity_config(
        self, activity: str, max_times: int, time_limit: int
    ):
        """æ›´æ–°æ´»åŠ¨é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO activity_configs (activity_name, max_times, time_limit)
                VALUES ($1, $2, $3)
                ON CONFLICT (activity_name) 
                DO UPDATE SET 
                    max_times = EXCLUDED.max_times,
                    time_limit = EXCLUDED.time_limit,
                    created_at = CURRENT_TIMESTAMP
                """,
                activity,
                max_times,
                time_limit,
            )
        self._cache.pop("activity_limits", None)

    async def delete_activity_config(self, activity: str):
        """åˆ é™¤æ´»åŠ¨é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM activity_configs WHERE activity_name = $1", activity
            )
            await conn.execute(
                "DELETE FROM fine_configs WHERE activity_name = $1", activity
            )
        self._cache.pop("activity_limits", None)

    # ========== ç½šæ¬¾é…ç½®æ“ä½œ ==========
    async def get_fine_rates(self) -> Dict:
        """è·å–æ‰€æœ‰ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM fine_configs")
            fines = {}
            for row in rows:
                activity = row["activity_name"]
                if activity not in fines:
                    fines[activity] = {}
                fines[activity][row["time_segment"]] = row["fine_amount"]
            return fines

    async def get_fine_rates_for_activity(self, activity: str) -> Dict:
        """è·å–æŒ‡å®šæ´»åŠ¨çš„ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT time_segment, fine_amount FROM fine_configs WHERE activity_name = $1",
                activity,
            )
            return {row["time_segment"]: row["fine_amount"] for row in rows}

    async def update_fine_config(
        self, activity: str, time_segment: str, fine_amount: int
    ):
        """æ›´æ–°ç½šæ¬¾é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO fine_configs (activity_name, time_segment, fine_amount)
                VALUES ($1, $2, $3)
                ON CONFLICT (activity_name, time_segment) 
                DO UPDATE SET 
                    fine_amount = EXCLUDED.fine_amount,
                    created_at = CURRENT_TIMESTAMP
                """,
                activity,
                time_segment,
                fine_amount,
            )

    async def get_work_fine_rates(self) -> Dict:
        """è·å–ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM work_fine_configs")
            fines = {}
            for row in rows:
                checkin_type = row["checkin_type"]
                if checkin_type not in fines:
                    fines[checkin_type] = {}
                fines[checkin_type][row["time_segment"]] = row["fine_amount"]
            return fines

    async def get_work_fine_rates_for_type(self, checkin_type: str) -> Dict:
        """è·å–æŒ‡å®šç±»å‹çš„ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT time_segment, fine_amount FROM work_fine_configs WHERE checkin_type = $1",
                checkin_type,
            )
            return {row["time_segment"]: row["fine_amount"] for row in rows}

    async def update_work_fine_rate(
        self, checkin_type: str, time_segment: str, fine_amount: int
    ):
        """æ›´æ–°ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO work_fine_configs (checkin_type, time_segment, fine_amount)
                VALUES ($1, $2, $3)
                ON CONFLICT (checkin_type, time_segment)
                DO UPDATE SET fine_amount = EXCLUDED.fine_amount
                """,
                checkin_type,
                time_segment,
                fine_amount,
            )

    async def clear_work_fine_rates(self, checkin_type: str):
        """æ¸…ç©ºä¸Šä¸‹ç­ç½šæ¬¾é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM work_fine_configs WHERE checkin_type = $1", checkin_type
            )

    # ========== æ¨é€è®¾ç½®æ“ä½œ ==========
    async def get_push_settings(self) -> Dict:
        """è·å–æ¨é€è®¾ç½®"""
        cache_key = "push_settings"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM push_settings")
            settings = {row["setting_key"]: bool(row["setting_value"]) for row in rows}
            self._set_cached(cache_key, settings, 300)
            return settings

    async def update_push_setting(self, key: str, value: bool):
        """æ›´æ–°æ¨é€è®¾ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO push_settings (setting_key, setting_value)
                VALUES ($1, $2)
                ON CONFLICT (setting_key) 
                DO UPDATE SET 
                    setting_value = EXCLUDED.setting_value,
                    created_at = CURRENT_TIMESTAMP
                """,
                key,
                1 if value else 0,
            )
        self._cache.pop("push_settings", None)

    # ========== ç»Ÿè®¡å’Œå¯¼å‡ºç›¸å…³ ==========
    async def get_group_statistics(
        self, chat_id: int, target_date: Optional[date] = None
    ) -> List[Dict]:
        """è·å–ç¾¤ç»„ç»Ÿè®¡ä¿¡æ¯"""
        if target_date is None:
            target_date = self.get_beijing_date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            users = await conn.fetch(
                """
                SELECT DISTINCT u.user_id, u.nickname, 
                    COALESCE(ua_total.total_accumulated_time, 0) as total_accumulated_time,
                    COALESCE(ua_total.total_activity_count, 0) as total_activity_count,
                    COALESCE(u.total_fines, 0) as total_fines,
                    COALESCE(u.overtime_count, 0) as overtime_count,
                    COALESCE(u.total_overtime_time, 0) as total_overtime_time
                FROM users u
                LEFT JOIN (
                    SELECT user_id, 
                        SUM(accumulated_time) as total_accumulated_time,
                        SUM(activity_count) as total_activity_count
                    FROM user_activities 
                    WHERE chat_id = $1 AND activity_date = $2
                    GROUP BY user_id
                ) ua_total ON u.user_id = ua_total.user_id
                WHERE u.chat_id = $1 
                AND EXISTS (
                    SELECT 1 FROM user_activities 
                    WHERE chat_id = $1 AND user_id = u.user_id AND activity_date = $2
                )
                """,
                chat_id,
                target_date,
            )

            result = []
            for user in users:
                user_data = dict(user)

                # è·å–æ´»åŠ¨è¯¦æƒ…
                activities = await conn.fetch(
                    """
                    SELECT activity_name, activity_count, accumulated_time
                    FROM user_activities
                    WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3
                    """,
                    chat_id,
                    user["user_id"],
                    target_date,
                )

                user_data["activities"] = {}
                for row in activities:
                    user_data["activities"][row["activity_name"]] = {
                        "count": row["activity_count"],
                        "time": row["accumulated_time"],
                    }

                result.append(user_data)

            return result

    async def get_all_groups(self) -> List[int]:
        """è·å–æ‰€æœ‰ç¾¤ç»„ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT chat_id FROM groups")
            return [row["chat_id"] for row in rows]

    async def get_group_members(self, chat_id: int) -> List[Dict]:
        """è·å–ç¾¤ç»„æˆå‘˜"""
        today = self.get_beijing_date()
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT user_id, nickname, current_activity, activity_start_time, total_accumulated_time, total_activity_count, total_fines, overtime_count, total_overtime_time FROM users WHERE chat_id = $1 AND last_updated = $2",
                chat_id,
                today,
            )
            return [dict(row) for row in rows]

    # ========== æœˆåº¦ç»Ÿè®¡ ==========
    async def get_monthly_statistics(
        self, chat_id: int, year: int = None, month: int = None
    ) -> List[Dict]:
        """ä¿®å¤ç‰ˆï¼šè·å–æœˆåº¦ç»Ÿè®¡ - æ­£ç¡®èšåˆç»Ÿè®¡å­—æ®µ"""

        if year is None or month is None:
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        statistic_date = date(year, month, 1)
        self._ensure_pool_initialized()

        async with self.pool.acquire() as conn:
            # ğŸ†• ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„èšåˆæ–¹å¼
            rows = await conn.fetch(
                """
                WITH user_base AS (
                    -- è·å–è¯¥æœˆä»½æœ‰è®°å½•çš„æ‰€æœ‰ç”¨æˆ·
                    SELECT DISTINCT user_id 
                    FROM monthly_statistics 
                    WHERE chat_id = $1 AND statistic_date = $2
                ),
                user_totals AS (
                    SELECT
                        ub.user_id,
                        u.nickname,
                        -- æ´»åŠ¨ç»Ÿè®¡ï¼šSUM èšåˆ
                        COALESCE(SUM(CASE WHEN ms.activity_name NOT IN 
                            ('work_days','work_hours','total_fines','overtime_count','overtime_time')
                            THEN ms.activity_count ELSE 0 END), 0) AS total_activity_count,
                    
                        COALESCE(SUM(CASE WHEN ms.activity_name NOT IN 
                            ('work_days','work_hours','total_fines','overtime_count','overtime_time')
                            THEN ms.accumulated_time ELSE 0 END), 0) AS total_accumulated_time,
                    
                        -- ğŸ†• ä¿®å¤ï¼šç½šæ¬¾ç»Ÿè®¡ä½¿ç”¨ SUM
                        COALESCE(SUM(CASE WHEN ms.activity_name = 'total_fines' 
                            THEN ms.accumulated_time ELSE 0 END), 0) AS total_fines,
                    
                        -- ğŸ†• ä¿®å¤ï¼šè¶…æ—¶å’Œå·¥ä½œç»Ÿè®¡ä½¿ç”¨å­æŸ¥è¯¢ï¼ˆå› ä¸ºæ¯ä¸ªç±»å‹åªæœ‰ä¸€æ¡è®°å½•ï¼‰
                        COALESCE((
                            SELECT ms2.activity_count 
                            FROM monthly_statistics ms2 
                            WHERE ms2.chat_id = $1 
                            AND ms2.user_id = ub.user_id 
                            AND ms2.statistic_date = $2 
                            AND ms2.activity_name = 'overtime_count'
                        ), 0) AS overtime_count,
                    
                        COALESCE((
                            SELECT ms2.accumulated_time 
                            FROM monthly_statistics ms2 
                            WHERE ms2.chat_id = $1 
                            AND ms2.user_id = ub.user_id 
                            AND ms2.statistic_date = $2 
                            AND ms2.activity_name = 'overtime_time'
                        ), 0) AS total_overtime_time,
                    
                        COALESCE((
                            SELECT ms2.activity_count 
                            FROM monthly_statistics ms2 
                            WHERE ms2.chat_id = $1 
                            AND ms2.user_id = ub.user_id 
                            AND ms2.statistic_date = $2 
                            AND ms2.activity_name = 'work_days'
                        ), 0) AS work_days,
                    
                        COALESCE((
                            SELECT ms2.accumulated_time 
                            FROM monthly_statistics ms2 
                            WHERE ms2.chat_id = $1 
                            AND ms2.user_id = ub.user_id 
                            AND ms2.statistic_date = $2 
                            AND ms2.activity_name = 'work_hours'
                        ), 0) AS work_hours
                    
                    FROM user_base ub
                    LEFT JOIN monthly_statistics ms ON ms.chat_id = $1 AND ms.user_id = ub.user_id AND ms.statistic_date = $2
                    LEFT JOIN users u ON u.chat_id = $1 AND u.user_id = ub.user_id
                    GROUP BY ub.user_id, u.nickname
                ),
                activity_details AS (
                    SELECT
                        ms.user_id,
                        jsonb_object_agg(
                            ms.activity_name, 
                            jsonb_build_object(
                                'count', ms.activity_count,
                                'time', ms.accumulated_time
                            )
                        ) AS activities
                    FROM monthly_statistics ms
                    WHERE ms.chat_id = $1 
                    AND ms.statistic_date = $2
                    AND ms.activity_name NOT IN 
                        ('work_days','work_hours','total_fines','overtime_count','overtime_time')
                    GROUP BY ms.user_id
                )
                SELECT 
                    ut.*,
                    COALESCE(ad.activities, '{}'::jsonb) AS activities
                FROM user_totals ut
                LEFT JOIN activity_details ad ON ut.user_id = ad.user_id
                ORDER BY ut.total_accumulated_time DESC
                """,
                chat_id,
                statistic_date,
            )

            # è½¬æ¢ä¸ºPythonå­—å…¸
            result = []
            for row in rows:
                data = dict(row)

                # ç¡®ä¿activitiesæ˜¯å­—å…¸æ ¼å¼
                activities = data.get("activities", {})
                if hasattr(activities, "copy"):  # å¦‚æœæ˜¯jsonbç±»å‹
                    data["activities"] = dict(activities)
                else:
                    data["activities"] = activities or {}

                result.append(data)

            return result

    async def get_monthly_work_statistics(
        self, chat_id: int, year: int = None, month: int = None
    ) -> List[Dict]:
        """è·å–æœˆåº¦ä¸Šä¸‹ç­ç»Ÿè®¡"""
        if year is None or month is None:
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        start_date = date(year, month, 1)
        if month == 12:
            end_date = date(year + 1, 1, 1)
        else:
            end_date = date(year, month + 1, 1)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT 
                    wr.user_id,
                    u.nickname,
                    COUNT(CASE WHEN wr.checkin_type = 'work_start' THEN 1 END) as work_start_count,
                    COUNT(CASE WHEN wr.checkin_type = 'work_end' THEN 1 END) as work_end_count,
                    SUM(CASE WHEN wr.checkin_type = 'work_start' THEN wr.fine_amount ELSE 0 END) as work_start_fines,
                    SUM(CASE WHEN wr.checkin_type = 'work_end' THEN wr.fine_amount ELSE 0 END) as work_end_fines
                FROM work_records wr
                JOIN users u ON wr.chat_id = u.chat_id AND wr.user_id = u.user_id
                WHERE wr.chat_id = $1 AND wr.record_date >= $2 AND wr.record_date < $3
                GROUP BY wr.user_id, u.nickname
                """,
                chat_id,
                start_date,
                end_date,
            )
            return [dict(row) for row in rows]

    async def get_monthly_activity_ranking(
        self, chat_id: int, year: int = None, month: int = None
    ) -> Dict[str, List]:
        """è·å–æœˆåº¦æ´»åŠ¨æ’è¡Œæ¦œ"""
        if year is None or month is None:
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        statistic_date = date(year, month, 1)
        activity_limits = await self.get_activity_limits()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rankings = {}
            for activity in activity_limits.keys():
                rows = await conn.fetch(
                    """
                    SELECT 
                        ms.user_id,
                        u.nickname,
                        ms.accumulated_time as total_time,
                        ms.activity_count as total_count
                    FROM monthly_statistics ms
                    JOIN users u ON ms.chat_id = u.chat_id AND ms.user_id = u.user_id
                    WHERE ms.chat_id = $1 AND ms.activity_name = $2 
                        AND ms.statistic_date = $3
                    ORDER BY ms.accumulated_time DESC
                    LIMIT 10
                    """,
                    chat_id,
                    activity,
                    statistic_date,
                )
                rankings[activity] = [dict(row) for row in rows]
            return rankings

    # ========== æ•°æ®æ¸…ç† ==========
    async def cleanup_old_data(self, days: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_date = (self.get_beijing_time() - timedelta(days=days)).date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                await conn.execute(
                    "DELETE FROM user_activities WHERE activity_date < $1", cutoff_date
                )
                await conn.execute(
                    "DELETE FROM work_records WHERE record_date < $1", cutoff_date
                )
                await conn.execute(
                    "DELETE FROM users WHERE last_updated < $1", cutoff_date
                )

    async def cleanup_monthly_data(self, target_date: date = None):
        """æ¸…ç†æœˆåº¦ç»Ÿè®¡æ•°æ®"""
        if target_date is None:
            today = self.get_beijing_time()
            monthly_cutoff = (today - timedelta(days=90)).date().replace(day=1)
            target_date = monthly_cutoff
        else:
            target_date = target_date.replace(day=1)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            result = await conn.execute(
                "DELETE FROM monthly_statistics WHERE statistic_date < $1", target_date
            )
            return (
                int(result.split()[-1]) if result and result.startswith("DELETE") else 0
            )

    async def cleanup_specific_month(self, year: int, month: int):
        """æ¸…ç†æŒ‡å®šå¹´æœˆçš„æœˆåº¦ç»Ÿè®¡æ•°æ®"""
        target_date = date(year, month, 1)
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            result = await conn.execute(
                "DELETE FROM monthly_statistics WHERE statistic_date = $1", target_date
            )
            return (
                int(result.split()[-1]) if result and result.startswith("DELETE") else 0
            )

    async def cleanup_inactive_users(self, days: int = 30):
        """æ¸…ç†é•¿æœŸæœªæ´»åŠ¨ç”¨æˆ·åŠå…¶è®°å½•ï¼ˆå®‰å…¨ç‰ˆï¼‰"""

        cutoff_date = (self.get_beijing_time() - timedelta(days=days)).date()

        async with self.pool.acquire() as conn:
            async with conn.transaction():

                # æ‰¾å‡ºè¦åˆ é™¤çš„ç”¨æˆ·åˆ—è¡¨ï¼ˆé¿å…ç›´æ¥åˆ ï¼‰
                users_to_delete = await conn.fetch(
                    """
                        SELECT user_id 
                        FROM users
                        WHERE last_updated < $1
                        AND NOT EXISTS (
                            SELECT 1 FROM monthly_statistics 
                            WHERE monthly_statistics.chat_id = users.chat_id 
                            AND monthly_statistics.user_id = users.user_id
                        )
                        """,
                    cutoff_date,
                )

                user_ids = [u["user_id"] for u in users_to_delete]

                if not user_ids:
                    logger.info("ğŸ§¹ æ— éœ€æ¸…ç†ç”¨æˆ·")
                    return 0

                # åˆ é™¤ç”¨æˆ·çš„æ—¥å¸¸è®°å½•
                await conn.execute(
                    "DELETE FROM user_activities WHERE user_id = ANY($1)",
                    user_ids,
                )

                # åˆ é™¤ä¸Šä¸‹ç­è®°å½•ï¼ˆå¦‚æœä½ éœ€è¦ï¼‰
                await conn.execute(
                    "DELETE FROM work_records WHERE user_id = ANY($1)",
                    user_ids,
                )

                # æœ€ååˆ é™¤ç”¨æˆ·
                deleted_count = await conn.execute(
                    "DELETE FROM users WHERE user_id = ANY($1)",
                    user_ids,
                )

        logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} ä¸ªé•¿æœŸæœªæ´»åŠ¨çš„ç”¨æˆ·ä»¥åŠä»–ä»¬çš„æ‰€æœ‰è®°å½•")
        return deleted_count

    # ========== æ´»åŠ¨äººæ•°é™åˆ¶ ==========
    async def set_activity_user_limit(self, activity: str, max_users: int):
        """è®¾ç½®æ´»åŠ¨äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO activity_user_limits (activity_name, max_users)
                VALUES ($1, $2)
                ON CONFLICT (activity_name)
                DO UPDATE SET 
                    max_users = EXCLUDED.max_users,
                    updated_at = CURRENT_TIMESTAMP
                """,
                activity,
                max_users,
            )
        self._cache.pop(f"activity_limit:{activity}", None)

    async def get_activity_user_limit(self, activity: str) -> int:
        """è·å–æ´»åŠ¨äººæ•°é™åˆ¶"""
        cache_key = f"activity_limit:{activity}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT max_users FROM activity_user_limits WHERE activity_name = $1",
                activity,
            )
            limit = row["max_users"] if row else 0
            self._set_cached(cache_key, limit, 60)
            return limit

    async def get_current_activity_users(self, chat_id: int, activity: str) -> int:
        """è·å–å½“å‰æ­£åœ¨è¿›è¡ŒæŒ‡å®šæ´»åŠ¨çš„ç”¨æˆ·æ•°é‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            count = await conn.fetchval(
                "SELECT COUNT(*) FROM users WHERE chat_id = $1 AND current_activity = $2",
                chat_id,
                activity,
            )
            return count or 0

    async def get_all_activity_limits(self) -> Dict[str, int]:
        """è·å–æ‰€æœ‰æ´»åŠ¨çš„äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT activity_name, max_users FROM activity_user_limits"
            )
            return {row["activity_name"]: row["max_users"] for row in rows}

    async def remove_activity_user_limit(self, activity: str):
        """ç§»é™¤æ´»åŠ¨äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM activity_user_limits WHERE activity_name = $1", activity
            )
        self._cache.pop(f"activity_limit:{activity}", None)

    # ========== å·¥å…·æ–¹æ³• ==========
    @staticmethod
    def format_seconds_to_hms(seconds: int) -> str:
        """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºå°æ—¶:åˆ†é’Ÿ:ç§’çš„å­—ç¬¦ä¸²"""
        if not seconds:
            return "0ç§’"

        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60

        if hours > 0:
            return f"{hours}å°æ—¶{minutes}åˆ†{secs}ç§’"
        elif minutes > 0:
            return f"{minutes}åˆ†{secs}ç§’"
        else:
            return f"{secs}ç§’"

    @staticmethod
    def format_time_for_csv(seconds: int) -> str:
        """ä¸ºCSVå¯¼å‡ºæ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if not seconds:
            return "0åˆ†0ç§’"

        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60

        if hours > 0:
            return f"{hours}æ—¶{minutes}åˆ†{secs}ç§’"
        else:
            return f"{minutes}åˆ†{secs}ç§’"

    async def connection_health_check(self) -> bool:
        """å¿«é€Ÿè¿æ¥å¥åº·æ£€æŸ¥"""
        if not self.pool:
            return False

        try:
            async with self.pool.acquire() as conn:
                result = await conn.fetchval("SELECT 1")
                return result == 1
        except Exception as e:
            logger.debug(f"æ•°æ®åº“è¿æ¥å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def get_database_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "type": "postgresql",
            "initialized": self._initialized,
            "cache_size": len(self._cache),
        }


# å…¨å±€æ•°æ®åº“å®ä¾‹
db = PostgreSQLDatabase()
